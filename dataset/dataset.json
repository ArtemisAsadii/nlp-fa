[
    {
        "title": "هوش_مصنوعی",
        "text": "هوش مصنوعی (به انگلیسی: Artificial intelligence) (مخفف انگلیسی: AI) هوشی است که توسط ماشین‌ها ظهور پیدا می‌کند، در مقابل هوش طبیعی که توسط جانوران شامل انسان‌ها نمایش می‌یابد. اما پیش از هرچیز باید این موضوع را دانست که کلمه هوش، نشان دهنده امکان استدلال است و اینکه آیا هوش مصنوعی می‌تواند به توانایی استدلال دست یابد یا خیر، خود موضوع اختلاف محققان است. کتاب‌های AI پیشرو، این شاخه را به عنوان شاخه مطالعه بر روی «عوامل هوشمند» تعریف می‌کنند: هر سامانه‌ای که محیط خود را درک کرده و کنش‌هایی را انجام می‌دهد که شانسش را در دستیابی به اهدافش بیشینه می‌سازد. برخی از منابع شناخته شده از اصطلاح «هوش مصنوعی» جهت توصیف ماشینی استفاده می‌کنند که عملکردهای «شناختی» را از روی ذهن انسان‌ها تقلید می‌کنند، همچون «یادگیری» و «حل مسئله»، با این حال این تعریف توسط محققان اصلی در زمینه AI رد شده است.\nکاربردهای هوش مصنوعی شامل موتورهای جستجو پیشرفتهٔ وب (مثل گوگل و بینگ)، سامانه توصیه‌گر (که توسط یوتیوب، آمازون و نتفلیکس استفاده می‌شوند)، فهم زبان انسان‌ها (همچون سیری، جمنای و آمازون الکسا)، خودروهای خودران (مثل تسلا)، هوش مصنوعی مولد یا خلاقیت محاسباتی (مثل چت‌جی‌پی‌تی یا تولید اثر هنری مانند دال-ئی و میدجرنی) تصمیم‌گیری خودکار و رقابت در بالاترین سطوح سامانه‌های بازی استراتژیک (همچون شطرنج و گو). با بیشتر شدن توانایی ماشین‌ها، وظایفی که نیازمند «هوشمندی» هستند اغلب از تعریف AI برداشته می‌شود، پدیده‌ای که به آن اثر هوش مصنوعی گفته می‌شود. به عنوان مثال، فهم نوری کاراکتر را اغلب از چیزهایی که AI در نظر گرفته می‌شوند مستثنی می‌کنند، چرا که این فناوری تبدیل به فناوری عادی و روزمره‌ای شده است.\nهوش مصنوعی در سال ۱۹۵۶ میلادی تبدیل به شاخه‌ای آکادمیک شد و در سال‌های پس از آن چندین موج خوش‌بینی را تجربه کرده و مجدد دچار امواج ناامیدی و کمبود بودجه شده (که به آن «زمستان AI» می‌گویند)، سپس فناوری‌های جدیدی در پی آن آمده و موفقیت و بودجه‌های تحقیقاتی این حوزه مجدداً احیا گشته‌اند. تحقیقات AI رهیافت‌های متفاوتی را از زمان تأسیسش امتحان کرده و آن‌ها را کنار گذاشته است، رهیافت‌هایی چون: شبیه‌سازی مغز، مدل‌سازی حل مسئله توسط مغز انسان، منطق صوری، بانک‌های اطلاعاتی بزرگ دانش و تقلید رفتار جانوران. در اولین دهه‌های قرن ۲۱ میلادی، یادگیری ماشینی که شدیداً از آمار ریاضیاتی بهره می‌برد در این حوزه غلبه داشت و این فناوری اثبات کرد که به شدت موفق است و به حل چندین مسئله چالش‌برانگیز در صنعت و فضای آکادمیک کمک نمود.\nشاخه‌های مختلف تحقیقات هوش مصنوعی حول اهداف به‌خصوصی متمرکز بوده و از ابزارآلات خاصی استفاده می‌کنند. اهداف سنتی تحقیقات AI شامل این موارد اند: استدلال، نمایش دانش، برنامه‌ریزی، یادگیری، پردازش زبان طبیعی، ادراک و توانایی در جابجایی و دستکاری اشیاء. هوش جامع (توانایی حل مسائل دلخواه) در میان اهداف بلند مدت این حوزه است. جهت حل چنین مسائلی، محققان AI فنون حل مسئله وسیع و یکپارچه‌ای را شامل این موارد به کار بسته‌اند: جست‌وجو و بهینه‌سازی ریاضیاتی، منطق صوری، شبکه‌های عصبی مصنوعی و روش‌های مبنی بر آمار، احتمالات و اقتصاد. AI همچنین با حوزه‌هایی چون علوم کامپیوتر، روان‌شناسی، زبان‌شناسی، فلسفه و بسیاری از حوزه‌های دیگر مرتبط است.\nاین شاخه بر این فرض بنا شده است که هوش انسانی «را می‌توان به دقت توصیف نمود، به طوری که می‌توان آن را توسط یک ماشین شبیه‌سازی نمود». این فرض بحث‌های فلسفی را پیرامون ذهن و اخلاقیات خلق موجودات هوشمند برانگیخته است، موجوداتی که دارای هوش شبیه-انسان اند. این مسائل توسط افسانه‌ها، داستان‌های تخیلی و فلسفه از زمان‌های باستان مورد کاوش واقع شده‌اند. ادبیات علمی-تخیلی و آینده‌پژوهی نیز پیشنهاد می‌دهند که AI با پتانسیل و قدرت عظیمی که دارد، ممکن است منجر به ایجاد ریسک وجودی برای بشریت گردد.\n\nتاریخچه\nهوش مصنوعی توسط فلاسفه و ریاضی‌دانانی نظیر جرج بول که اقدام به ارائهٔ قوانین و نظریه‌هایی در مورد منطق نمودند، مطرح شده بود. با اختراع رایانه‌های الکترونیکی در سال ۱۹۴۳، هوش مصنوعی، دانشمندان آن زمان را به چالشی بزرگ فراخواند. در این شرایط، چنین به‌نظر می‌رسید که این فناوری قادر به شبیه‌سازی رفتارهای هوشمندانه خواهد بود.\nبا وجود مخالفت گروهی از متفکران با هوش مصنوعی که با تردید به کارآمدی آن می‌نگریستند تنها پس از چهار دهه، شاهد تولد ماشین‌های شطرنج باز و دیگر سامانه‌های هوشمند در صنایع گوناگون شدیم.\nحوزه پژوهش در زمینه هوش مصنوعی در یک کارگاه آموزشی در کالج دارتموث در سال ۱۹۵۶ متولد شد. شرکت‌کنندگان آلن نیول (دانشگاه کارنگی ملون)، هربرت سیمون (دانشگاه کارنگی ملون)، جان مک‌کارتی (مؤسسه فناوری ماساچوست)، ماروین منسکی (مؤسسه فناوری ماساچوست) و آرتور ساموئل (آی‌بی‌ام) از بنیان‌گذاران و رهبران پژوهش در زمینه هوش مصنوعی شدند. آن‌ها به همراه دانشجویانشان برنامه‌هایی نوشتند که مطبوعات آن را «شگفت‌آور» توصیف می‌کردند، رایانه‌ها استراتژی‌های بردِ بازی چکرز را فرا می‌گرفتند، سوالاتی در جبر حل می‌کردند، قضیه‌های منطقی اثبات می‌کردند و انگلیسی صحبت می‌کردند. در اواسط دهه ۱۹۶۰ میلادی وزارت دفاع آمریکا سرمایه‌گذاری‌های سنگینی در حوزه پژوهش در زمینه هوش مصنوعی انجام می‌داد، در آن دهه آزمایشگاه‌های فراوانی در سراسر جهان تأسیس شد. بنیانگذاران هوش مصنوعی در مورد آینده خوشبین بودند: هربرت سیمون پیش‌بینی کرد «ماشین‌ها ظرف بیست سال قادر به انجام هر کاری هستند که یک انسان می‌تواند انجام دهد». ماروین مینسکی، نوشت: «در طی یک نسل … مسئله هوش مصنوعی اساساً حل خواهد شد».\nنام هوش مصنوعی در سال ۱۹۶۵ میلادی به عنوان یک دانش جدید ابداع گردید. البته فعالیت در این زمینه از سال ۱۹۶۰ میلادی شروع شد. (مرجع۱)\nبیشتر کارهای پژوهشی اولیه در هوش مصنوعی بر روی انجام ماشینی بازی‌ها و نیز اثبات قضیه‌های ریاضی با کمک رایانه‌ها بود. در آغاز چنین به نظر می‌آمد که رایانه‌ها قادر خواهند بود چنین فعالیت‌هایی را تنها با بهره گرفتن از تعداد بسیار زیادی کشف و جستجو برای مسیرهای حل مسئله و سپس انتخاب بهترین روش برای حل آن‌ها به انجام رسانند.\nاصطلاح هوش مصنوعی برای اولین بار توسط جان مک‌کارتی (که از آن به‌عنوان پدر علم و دانش تولید ماشین‌های هوشمند یاد می‌شود) استفاده شد. وی مخترع یکی از زبان‌های برنامه‌نویسی هوش مصنوعی به نام لیسپ (به انگلیسی: lisp) است. با این عنوان می‌توان به هویت رفتارهای هوشمندانه یک ابزار مصنوعی پی برد. (ساختهٔ دست بشر، غیرطبیعی، مصنوعی) حال آنکه هوش مصنوعی به عنوان یک اصطلاح عمومی پذیرفته شده که شامل محاسبات هوشمندانه و ترکیبی (مرکب از مواد مصنوعی) است.\nاز اصطلاح \"Strong and Weak AI\" می‌توان تا حدودی برای معرفی رده‌بندی سامانه‌ها استفاده کرد.\n\nآزمون تورینگ\nآزمون تورینگ آزمونی است که توسط آلن تورینگ در سال ۱۹۵۰ در نوشته‌ای به نام «محاسبات و هوشمندی» مطرح شد. در این آزمون شرایطی فراهم می‌شود که شخصی با ماشینی تعامل برقرار کند و پرسش‌های کافی برای بررسی اقدامات هوشمندانهٔ ماشین، از آن بپرسد. چنانچه در پایان آزمایش نتواند تشخیص دهد که با انسان یا با ماشین در تعامل بوده است، آزمون با موفقیت انجام شده است. تاکنون هیچ ماشینی از این آزمون با موفقیت بیرون نیامده است. کوشش این آزمون برای تشخیص درستی هوشمندی یک سامانه است که سعی در شبیه‌سازی انسان دارد.\n\nتعریف و طبیعت هوش مصنوعی\nهنوز تعریف دقیقی برای هوش مصنوعی که مورد توافق دانشمندان این علم باشد ارائه نشده است و این به هیچ وجه مایهٔ تعجب نیست. چرا که مقولهٔ مادر و اساسی‌تر از آن، یعنی خود هوش هم هنوز به‌طور همه‌جانبه و فراگیر تن به تعریف نداده است. در واقع می‌توان نسل‌هایی از دانشمندان را سراغ گرفت که تمام دوران زندگی خود را صرف مطالعه و تلاش در راه یافتن جوابی به این سؤال عمده نموده‌اند که: هوش چیست؟\nاما اکثر تعریف‌هایی که در این زمینه ارائه شده‌اند بر پایه یکی از ۴ باور زیر قرار می‌گیرند:\n\nسامانه‌هایی که به‌طور منطقی فکر می‌کنند\nسامانه‌هایی که به‌طور منطقی عمل می‌کنند\nسامانه‌هایی که مانند انسان فکر می‌کنند\nسامانه‌هایی که مانند انسان عمل می‌کنند (مرجع۱)\nشاید بتوان هوش مصنوعی را این‌گونه توصیف کرد: «هوش مصنوعی عبارت است از مطالعه این که چگونه رایانه‌ها را می‌توان وادار به کارهایی کرد که در حال حاضر انسان‌ها آن‌ها را صحیح یا بهتر انجام می‌دهند» (مرجع۲). هوش مصنوعی به هوشی که یک ماشین از خود نشان می‌دهد یا به دانشی در کامپیوتر که سعی در ایجاد آن دارد گفته می‌شود. بیشتر نوشته‌ها و مقاله‌های مربوط به هوش مصنوعی آن را «دانش شناخت و طراحی عامل‌های هوشمند» تعریف کرده‌اند. یک عامل هوشمند، ساماندهی است که با شناخت محیط اطراف خود، شانس موفقیت خود را بالا می‌برد.\nاینکه هوش مصنوعی چیست و چه تعریفی می‌توان از آن بیان نمود؟ مبحثی است که تاکنون دانشمندان به یک تعریف جامع در آن نرسیده‌اند و هریک تعریفی را ارائه نموده‌اند که در زیر نمونه‌ای از این تعاریف آمده است.\n\nهنر ایجاد ماشین‌هایی که وظایفی را انجام می‌دهند که انجام آن‌ها توسط انسان‌ها نیاز به هوش دارد (کورزویل- ۱۹۹۰)\nمطالعهٔ استعدادهای ذهنی از طریق مدل‌های محاسباتی (کارنیاک و مک درموت - ۱۹۸۵)\nمطالعهٔ اینکه چگونه رایانه‌ها را قادر به انجام اعمالی کنیم که در حال حاضر، انسان آن اعمال را بهتر انجام می‌دهد. (ریچ و نایت -۱۹۹۱)\nخودکارسازی فعالیت‌هایی که ما آن‌ها را به تفکر انسانی نسبت می‌دهیم. فعالیت‌هایی مثل تصمیم‌گیری، حل مسئله، یادگیری و … (بلمن -۱۹۷۸)\nتلاشی نو و مهیج برای اینکه رایانه‌ها را قادر به فکر کردن کنیم. ماشین‌هایی با فکر و حس تشخیص واقعی (هاگلند-۱۹۸۵)\nیک زمینهٔ تخصصی که به دنبال توضیح و شبیه‌سازی رفتار هوشمندانه به وسیلهٔ فرایندهای رایانه‌ای است. (شالکوف -۱۹۹۰)\nمطالعه محاسباتی که درک، استدلال و عمل کردن را توسط ماشین‌ها را ممکن می‌سازد. (وینستون - ۱۹۹۲)\nتوانایی دست یافتن به کارایی در حد انسان در همهٔ امور شناختی توسط رایانه (آلن تورینگ – ۱۹۵۰)\nهوش مصنوعی دانش و مهندسی ساخت ماشین‌های هوشمند و به خصوص برنامه‌های رایانه‌ای هوشمند است. هوش مصنوعی با وظیفه مشابه استفاده از رایانه‌ها برای فهم چگونگی هوش انسان مرتبط است، اما مجبور نیست خودش را به روش‌هایی محدود کند که بیولوژیکی باشند. (جان مک‌کارتی – ۱۹۸۰)\nهوشمندی مفهومی نسبی دارد و نمی‌توان محدوده صحیحی را برای ارائه تعریف از آن مشخص نمود. رفتاری که از نظر یک فرد هوشمند به نظر می‌رسد؛ ممکن است برای یک فرد دیگر این‌گونه به نظر نرسد. اما در مجموع خصوصیات زیر قابلیت‌های ضروری برای هوشمندی است:\n\nپاسخ به موقعیت‌های از قبل تعریف نشده با انعطاف بسیار بالا و بر اساس بانک دانش\nمعنا دادن به پیام‌های نادرست یا مبهم\nدرک تمایزها و شباهت‌ها\nتجزیه و تحلیل اطلاعات و نتیجه‌گیری\nتوانمندی آموختن و یادگرفتن\nبرقراری ارتباط دوطرفه\nبه فرض اینکه تعاریف بالا را از هوشمندی بپذیریم، موارد زیر فهرستی است از وظایفی که از یک سامانه هوشمند انتظار می‌رود و تقریباً اکثر دانشمندان هوش مصنوعی بر آن توافق نظر دارند به شرح زیر است:\n\nتولید گفتار\nتشخیص و درک گفتار (پردازش زبان طبیعی انسان)\nدستورپذیری و قابلیت انجام اعمال فیزیکی در محیط طبیعی و مجازی\nاستنتاج و استدلال\nتشخیص الگو و بازشناسی الگو برای پاسخ گویی به مسائل بر اساس دانش قبلی\nشمایلی گرافیکی یا فیزیکی جهت ابراز احساسات و عکس‌العمل‌های ظریف\nسرعت عکس‌العمل بالا\n\nرویکردهای اصلی به هوش مصنوعی\nرویکردهای شاخص به هوش مصنوعی (به ترتیب روند زمانی که مطرح شدند و البته همگی سپس به بقا در حیطه خودشان ادامه دادند):\n1- مبتنی بر منطق و Rule\n2- مبتنی بر تشخیص الگو / روش‌های احتمالاتی / روش‌های آماری\n3- مبتنی بر الگوریتمهای مکاشفه ای (Heuristics)\n4- مبتنی بر گراف‌های دانش و هستان‌شناسی‌ها\n5- مبتنی بر هوش مصنوعی عامل گرا\n6- مبتنی بر یادگیری ماشین\n7- مبتنی بر شبکه‌های عصبی عمیق\n8- مبتنی بر GAN و Transformers و Encoders و Decoders و هوش مصنوعی مولد (Generative AI)\n9- مبتنی بر مدل‌های بزرگ آموزش داده شده\n10- مبتنی بر مدل‌های بزرگ زبانی LLM\n11- مبتنی بر دستوردهی به LLMها (یعنی Prompt Engineering)\n12- هوش مصنوعی توضیح پذیر (XAI) / اعتماد پذیر / مسئول / جویا (RAG)\n13- هوش مصنوعی انسان وار (Human Like) و معماری شناختی\n14- هوش مصنوعی عمومی (AGI)\n15- ابرهوش مصنوعی (ASI)\n16- خِرَد ترکیبی (Hybrid Wisdom)\n\nکاربردهای هوش مصنوعی\nهوش مصنوعی کاربردهای متنوعی دارد. تعدادی از مهم‌ترین کاربردهای هوش مصنوعی شامل استفاده در وسایل نقلیه خودگردان (مثل پهپادها و اتومبیل‌های خودران)، تشخیص‌های پزشکی، خلق آثار هنری، اثبات قضیه‌های ریاضی، انجام بازی‌های فکری، تعیین هویت تصاویر(تشخیص چهره) و صداها، ذخیره انرژی، جستجوگرهای اینترنتی، تهیه قراردادها و پیش‌بینی آرای قضایی می‌شوند.\n\nهوش مصنوعی در اقتصاد\nیکی از مهم‌ترین کاربردهای هوش مصنوعی در زمینهٔ تجارت، اقتصاد و کلان داده است. برای مثال، با استفاده از هوش مصنوعی می‌توان با ضریب خطای پایینی، تغییرات فصلی و بلندمدت در عرضه یا تقاضای محصولات مختلف را پیش‌بینی کرد. این موضوع می‌تواند به شدت در سیاست، اقتصاد کلان و کنترل عرضه و تقاضا مفید واقع شود. همچنین، شرکت‌هایی مانند گوگل خدماتی در زمینهٔ هوش مصنوعی به شرکت‌های بزرگ ارائه می‌دهند که می‌تواند به برنامه‌ریزی، انبارگردانی، پیش‌بینی سیر صعودی یا نزولی فروش در محصولات به خصوص و نیز برندسازی آن‌ها کمک کند.\nپیش‌بینی قیمت در بازارها (مانند پیش‌بینی قیمت نفت با هوش مصنوعی) یکی از کاربردهای هوش مصنوعی در اقتصاد است.\n\nهوش مصنوعی در ورزش\nبه‌طور تاریخی، پیش‌بینی فوتبال به انسان‌های ماهری وابسته بود که می‌توانستند سوابق و وضعیت دو تیم و بازیکنان را تحلیل کنند. با انقلاب دیجیتال، سایت‌های شرط‌بندی کار را برای پیش‌بینی آسان و آسان‌تر کردند. اما حتی ظهور سایت‌ها و شرط‌بندی آنلاین هم تأثیری در نحوه شرط‌بندی ایجاد نکرد. همچنان علاقه‌مندان تلاش می‌کنند تا وضعیت طرفین و بازیکنان را بررسی کنند. هوش مصنوعی این را تغییر می‌دهد. اینترنت باعث ظهور سایت‌ها و فروم‌هایی شد که تیپسترهای شرط‌بندی فرم معرفی می‌کنند. با ظهور هوش مصنوعی، فرم شرط‌بندی می‌تواند چیزی فراتر از یک محاسبه انسانی باشد و الگوریتم‌های یادگیری ماشین، بازی را عوض می‌کنند.\n\nشبکه‌های اجتماعی\nدر شبکه‌های اجتماعی مطرح مانند توئیتر یا اینستاگرام، برای تشخیص الگوهای رفتاری انسانی، جلوگیری از هرزنامه و انتشار محتوای مجرمانه و نیز شناسایی مخاطبان هدف برای تبلیغات، از هوش مصنوعی استفاده می‌شود. همچنین، برخی از ربات‌های شبکهُ اجتماعی بر پایهٔ هوش مصنوعی فعالیت می‌کنند تا در بالاترین سطوح رفتارهای انسانی را شبیه‌سازی نمایند.\n\nهوش مصنوعی در خدمات حقوقی\nکاربرد هوش مصنوعی در خدمات حقوقی به سرعت در حال افزایش است و سیستم‌های نوین مبتنی بر پردازش زبان طبیعی به تدریج در حال به عهده گرفتن بخشی از وظایف حقوق‌دانان هستند. نرم‌افزارهای مبتنی بر تکنولوژی هوش مصنوعی در حال حاضر امکان تهیه قراردادهای دقیق، تحلیل قراردادها و اسناد حقوقی موجود و پیش‌بینی آرای دادگاه‌ها را فراهم کرده‌اند.\n\nهوش مصنوعی در فرهنگ، میراث فرهنگی و میراث مکتوب\nهوش مصنوعی از طریق فناوری‌ها و کاربردهای خود می‌تواند به توسعه فرهنگ، کاربردها و ابزارهای فرهنگی، حفاظت از میراث فرهنگی و میراث مکتوب یاری برساند. مواردی مانند پردازش زبان طبیعی، جست و جوی معنایی، خوانش رایانشی کتابها، متن کاوی، ایده کاوی، روانکاوی رایانشی، قرآن کاوی رایانشی، مدلهای زبانی بزرگ، نویسه خوانی نوری OCR (برای کتب خطی و قدیمی یا چاپی و جدید)، اکتشافات زبانشناسی، اکتشافات فرهنگی، پایگاه‌های داده و دادگان مرجع زبانی و فرهنگی و میراثی، دوقلوی دیجیتال برای میراث فرهنگی، دوقلوی دیجیتال برای میراث مکتوب، واقعیت مجازی هوشمند و واقعیت افزوده هوشمند برای میراث فراهنگی و دیگر موارد.\n\nفلسفه هوش مصنوعی\nبه‌طور کلی ماهیت وجودی هوش به مفهوم جمع‌آوری اطلاعات، استقراء و تحلیل تجربیات به منظور رسیدن به دانش یا ارائه تصمیم است. در واقع هوش به مفهوم به‌کارگیری تجربه به منظور حل مسائل دریافت شده تلقی می‌شود. هوش مصنوعی علم و مهندسی ایجاد ماشین‌هایی هوشمند با به‌کارگیری از کامپیوتر و الگوگیری از درک هوش انسانی یا حیوانی و نهایتاً دستیابی به مکانیزم هوش مصنوعی در سطح هوش انسانی است.\nدر مقایسهٔ هوش مصنوعی با هوش انسانی می‌توان گفت که انسان قادر به مشاهده و تجزیه و تحلیل مسائل در جهت قضاوت و اخذ تصمیم است در حالی که هوش مصنوعی مبتنی بر قوانین و رویه‌هایی از قبل تعبیه شده بر روی کامپیوتر است. در نتیجه علی‌رغم وجود رایانه‌های بسیار کارا و قوی در عصر حاضر ما هنوز قادر به پیاده کردن هوشی نزدیک به هوش انسان در ایجاد هوش‌های مصنوعی نبوده‌ایم.\nبه‌طور کلّی، هوش مصنوعی را می‌توان از زوایای متفاوتی مورد بررسی و مطالعه قرار داد. مابین هوش مصنوعی به عنوان یک هدف، هوش مصنوعی به عنوان یک رشتهٔ تحصیلی دانشگاهی یا هوش مصنوعی به عنوان مجموعهٔ فنون و راهکارهایی که توسط مراکز علمی مختلف و صنایع گوناگون تنظیم و توسعه یافته است، باید تفاوت قائل بود.\n\nاتاق چینی\nاتاق چینی یک آزمایش ذهنی است که اولین بار توسط مقاله جان سرل به‌نام «ذهن‌ها، مغزها، و برنامه‌ها» (به انگلیسی: Minds, Brains, and Programs) در مجله «علوم رفتاری و ذهنی» (به انگلیسی: Behavioral and Brain Sciences) در سال ۱۹۸۰ منتشر شد. وی با این سؤال که آیا یک برنامه هوشمند مترجم که توانایی ترجمه از زبان چینی به زبان انگلیسی را دارد، ضرورتی برای فهم موضوع مورد ترجمه دارد یا خیر و با تشبیه ذهن به یک برنامهٔ هوشمند رایانه‌ای این استدلال را در برابر مواضع فلسفی کارکردگرایی و نظریه محاسباتی ذهن که در آن‌ها، ذهن به عنوان یک محاسبه‌گر یا دستکاری کنندهٔ نماد عمل می‌کند، قرار داد. در واقع نتایج حاصل از آزمایش اتاق چینی حکایت از این دارد که هیچ برنامه‌ای نمی‌تواند به کامپیوتر ذهن، فهم یا آگاهی بدهد. حال آن برنامه هر آنچه می‌خواهد هوشمند باشد و باعث شود کامپیوتر همچون انسان رفتار کند. اگر چه این آزمایش در اصل جوابی برای اظهارات محققان هوش مصنوعی بود، اما این ادعا در برابر اهداف تحقیقات هوش مصنوعی قرار نمی‌گیرد چرا که این موضوع حدی برای هوشمندی کامپیوتر قائل نیست. همچنین این آزمایش مختص رایانه‌های دیجیتال است و دامنه آن همه ماشین‌ها نیستند.\n\nچگونگی استفاده هوش مصنوعی\nهوش مصنوعی چگونه استفاده می‌شود؟\nبه‌طور کلی هوش مصنوعی به دو دسته زیر تفکیک می‌شود:\nNarrow AI یا هوش مصنوعی ضعیف: این نوع هوش مصنوعی در یک زمینه محدود عمل می‌کند و شبیه‌سازی هوش انسانی است. هوش مصنوعی ضعیف اغلب بر روی یک کار مشخص تعریف می‌شود و در محدوده تعریفش بسیار عالی عمل می‌کند. شاید این ماشین‌ها بسیار هوشمند به نظر برسند اما حقیقت این است که حتی از ابتدائی‌ترین سطوح هوش انسانی هم ساده‌تر عمل می‌کنند.\nArtificial General Intelligence یا هوش مصنوعی عمومی: که با عنوان هوش مصنوعی قوی هم شناخته می‌شود، نوعی از هوش مصنوعی است که بیشتر در فیلم‌ها دیده‌ایم، مانند ربات‌های فیلم Westworld. هوش مصنوعی قوی بسیار شبیه به انسان عمل می‌کند چنان‌که می‌تواند توانایی‌های خود را بر حل مسائلی در حوزه‌های مختلف به کار بگیرد.\n\nمدیریت پیچیدگی\nایجاد و ابداع فنون و تکنیک‌های لازم برای مدیریت پیچیدگی را باید به عنوان هستهٔ بنیادین تلاش‌های علمی و پژوهشی گذشته، حال و آینده در تمامی زمینه‌های علوم رایانه و به ویژه در هوش مصنوعی معرفی کرد. شیوه‌ها و تکنیک‌های هوش مصنوعی در واقع، برای حل آن دسته از مسائل به وجود آمده است که به‌طور سهل و آسان توسط برنامه‌نویسی تابعی یا شیوه‌های ریاضی قابل حلّ نبوده‌اند.\nدر بسیاری از موارد، با پوشانیدن و پنهان ساختن جزئیّات فاقد اهمیت است که بر پیچیدگی فائق می‌آییم و می‌توانیم بر روی بخش‌هایی از مسئله متمرکز شویم که مهم‌تر است. تلاش اصلی در واقع، ایجاد و دستیابی به لایه‌ها و ترازهای بالاتر از هوشمندی انتزاع را نشانه می‌رود تا آنجا که سرانجام، برنامه‌های رایانه‌ای درست در همان سطحی کار خواهند کرد که خود انسان‌ها رسیده‌اند.\nبه یاری پژوهش‌های گستردهٔ دانشمندان علوم مرتبط، هوش مصنوعی تاکنون راه بسیاری پیموده است. در این راستا، تحقیقاتی که بر روی توانایی آموختن زبان‌ها انجام گرفت و همچنین درک عمیق از احساسات، دانشمندان را در پیشبرد این دانش کمک زیادی کرده است. یکی از اهداف متخصصین، تولید ماشین‌هایی است که دارای احساسات بوده و دست کم نسبت به وجود خود و احساسات خود آگاه باشند. این ماشین باید توانایی تعمیم تجربیات قدیمی خود در شرایط مشابه جدید را داشته و به این ترتیب اقدام به گسترش دامنه دانش و تجربیاتش کند.\nبرای نمونه ربات هوشمندی که بتواند اعضای بدن خود را به حرکت درآورد، نسبت به این حرکت خود آگاه بوده و با آزمون و خطا، دامنه حرکت خود را گسترش می‌دهد و با هر حرکت موفقیت‌آمیز یا اشتباه، دامنه تجربیات خود را وسعت بخشیده و سر انجام راه رفته یا حتی می‌دود یا به روشی برای جابجا شدن دست می‌یابد که سازندگانش برای او متصور نبوده‌اند.\nهر چند نمونه بالا ممکن است کمی آرمانی به نظر برسد، ولی به هیچ عنوان دور از دسترس نیست. دانشمندان عموماً برای تولید چنین ماشین‌هایی از وجود مدل‌های زنده‌ای که در طبیعت وجود به ویژه آدمی نیز سود برده‌اند.\nهوش مصنوعی اکنون در خدمت توسعه علوم رایانه نیز هست. زبان‌های برنامه‌نویسی پیشرفته، که توسعه ابزارهای هوشمند را ممکن ساخته‌اند، پایگاه‌های داده‌ای پیشرفته، موتورهای جستجو، و بسیاری نرم‌افزارها و ماشین‌ها از نتایج پژوهش‌هایی در راستای هوش مصنوعی بوده‌اند.\nاز زبان‌های برنامه‌نویسی هوش مصنوعی می‌توان به لیسپ، پرولوگ، کلیپس و ویپی اکسپرت اشاره کرد.\n\nشاخه‌های هوش مصنوعی در دانش رایانه\nشاخه‌های گوناگونی از هوش مصنوعی در دانش‌های رایانه‌ای مورد استفاده قرار می‌گیرند، برخی این شاخه‌ها عبارتند از:\n\nیادگیری ماشین (به انگلیسی: Machine Learning)\nشبکهٔ عصبی مصنوعی (به انگلیسی: Neural Networks)\nبینایی ماشین (به انگلیسی: Machine Vision)\nسامانه‌های خبره (به انگلیسی: Expert System)\nپردازش زبان طبیعی (به انگلیسی: NLP)\nالگوریتم ژنتیک (به انگلیسی: Genetic Algorithm)\nمفاهیم مرتبط با روباتیک (به انگلیسی: Robotic)\n\nتکنیک‌ها و زبان‌های برنامه‌نویسی هوش مصنوعی\nعملکرد اولیهٔ برنامه‌نویسی هوش مصنوعی ایجاد ساختار کنترلی مورد لزوم برای محاسبهٔ سمبولیک است. از مهم‌ترین و پرکاربردترین زبان برای هوش مصنوعی می‌توان از پایتون نام برد و در کنار آن زبان‌های برنامه‌نویسی لیسپ و پرولوگ علاوه بر اینکه از مهم‌ترین زبان‌های مورد استفاده در هوش مصنوعی هستند خصوصیات نحوی و معنایی آن‌ها باعث شده که آن‌ها شیوه‌ها و راه حل‌های قوی برای حل مسئله ارائه کنند.\nتأثیر قابل توجه این زبان‌ها بر روی توسعه هوش مصنوعی از جمله توانایی‌های آن‌ها به عنوان ابزارهای فکر کردن است. در حقیقت همان‌طور که هوش مصنوعی مراحل رشد خود را طی می‌کند، زبان‌های لیسپ و پرولوگ بیشتر مطرح می‌شوند که این زبان‌ها کار خود را در محدودهٔ توسعه سامانه‌های هوش مصنوعی در صنعت و دانشگاه‌ها دنبال می‌کنند و طبیعتاً اطلاعات در مورد این زبان‌ها به عنوان بخشی از مهارت هر برنامه‌نویس هوش مصنوعی است.\n\nپرولوگ: یک زبان برنامه‌نویسی منطقی است. یک برنامهٔ منطقی دارای یک سری ویژگی‌های قانون و منطق است. در حقیقت خود این نام از برنامه‌نویسی PRO در LOGIC می‌آید. در این زبان یک مفسر برنامه را بر اساس یک منطق می‌نویسد. ایدهٔ استفادهٔ توصیفی محاسبهٔ اولیه برای بیان خصوصیات حل مسئله یکی از محوریت‌های پرولوگ است که برای علم کامپیوتر به‌طور کلی و به‌طور جزئی برای زبان برنامه‌نویسی هوشمند مورد استفاده قرار می‌گیرند.\nلیسپ: اصولاً یک زبان کامل است که دارای عملکردها و لیست‌های لازمه برای توصیف عملکردهای جدید، تشخیص تناسب و ارزیابی معانی است. لیسپ به برنامه‌نویس قدرت کامل برای اتصال به ساختارهای اطلاعاتی را می‌دهد. گر چه لیسپ یکی از قدیمی‌ترین زبان‌های محاسباتی است که هنوز فعال است ولی دقت کافی در برنامه‌نویسی و طراحی توسعه باعث شده است که این یک زبان برنامه‌نویسی فعال باقی بماند. در حقیقت این مدل برنامه‌نویسی طوری مؤثر بوده است که تعدادی از دیگر زبان‌ها مانند اف پی، ام‌ال و اسکیم براساس عملکرد برنامه‌نویسی آن بنا شده‌اند. یکی از مهم‌ترین برنامه‌های مرتبط با لیسپ برنامهٔ اسکیم است که یک تفکر دوباره در بارهٔ زبان در آن وجود دارد که به وسیلهٔ توسعه هوش مصنوعی و برای آموزش و اصول علم کامپیوتر مورد استفاده قرار می‌گیرد.\nاستفاده از رابط‌های برنامه‌نویسی یا همان API می‌تواند استفاده از هوش مصنوعی در پروژه‌های برنامه‌نویسی را بسیار ساده‌تر سازد. APIهای هوش مصنوعی، رابط‌های RESTful هستند که به برنامه‌نویس اجازه می‌دهند به کمک مدل‌های از پیش تمرین داده شده شرکت‌های مختلف استفاده کنند و قابلیت‌های مرتبط با هوش مصنوعی نرم‌افزار خود را گسترش دهند در واقع در API برنامه‌ها از قابلیت‌های کاربردی یکدیگر استفاده می‌نمایند تا توانایی خود را افزایش دهند به‌طور مثال برنامه‌های مسیریابی از API نقشه گوگل و مسیریابی ترافیک ماهواره ای گوگل بهره می‌برند و توانایی خود را بسیار بهبود می‌بخشند. برای معرفی برخی از این APIهای هوش مصنوعی می‌توان از Wit.ai, Api.ai و ملیسا نام برد.\n\nعامل‌های هوشمند\nعامل‌ها (به انگلیسی: Agents) قادر به شناسایی الگوها و تصمیم‌گیری بر اساس قوانین فکر کردن خود هستند. قوانین و چگونگی فکر کردن هر عامل در راستای دستیابی به هدفش، تعریف می‌شود. این سامانه‌ها بر اساس قوانین خاص خود فکر کرده و کار خود را به درستی انجام می‌دهند. پس عاقلانه رفتار می‌کنند، هر چند الزاماً مانند انسان فکر نمی‌کنند.\nدر بحث هوشمندی اصطلاح پیس (به انگلیسی: PEAS) سرنام واژه‌های \"کارایی (به انگلیسی: Performance)\"، \"محیط (به انگلیسی: Environment)\"، \"اقدام گر (به انگلیسی: Agent)\" و \"حسگر (به انگلیسی: Sensor)\" است.\n\nسامانه‌های خبره\nسامانه‌های خبره زمینه‌ای پرکاربرد در هوش مصنوعی و مهندسی دانش است که با توجه به نیاز روزافزون جوامع بر اتخاذ راه حل‌ها و تصمیمات سریع در مواردی که دانش‌های پیچیده و چندگانهٔ انسانی مورد نیاز است و بر اهمیت نقش آن‌ها نیز افزوده می‌شود. سامانه‌های خبره به حل مسائلی می‌پردازند که به‌طور معمول نیازمند تخصص‌های کاردانان و متخصّصان انسانی است. به‌منظور توانایی بر حل مسائل در چنین سطحی (ترازی)، دسترسی هرچه بیشتر این‌گونه سامانه‌ها به دانش موجود در آن زمینه خاص ضروری می‌گردد.\n\nبرترین کتاب‌های هوش مصنوعی\nبسیاری از متخصصان، دانشجویان و علاقه‌مندان برای یادگیری مفاهیم بنیادی و پیشرفته این حوزه به کتاب‌های معتبر و آموزشی مراجعه می‌کنند. در این بخش، برخی از برترین کتاب‌های هوش مصنوعی که توسط دانشمندان برجسته این حوزه نوشته شده‌اند، معرفی می‌شوند.\n\nکتاب‌های کلاسیک و پایه‌ای\nArtificial Intelligence: A Modern Approach – نوشتهٔ استوارت راسل و پیتر نورویگ، این کتاب یکی از پرکاربردترین منابع در دانشگاه‌ها برای یادگیری اصول و مبانی هوش مصنوعی است.\n\nکتاب‌های تخصصی و پیشرفته\nDeep Learning – اثر یان لیکان، یوشوا بنجیو و جفری هینتون، که یکی از مراجع معتبر در زمینه یادگیری عمیق محسوب می‌شود.\n\nمنابع جدید و کاربردی\nHands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow – نوشتهٔ اورلیان ژرون، که به آموزش عملی یادگیری ماشین و یادگیری عمیق با استفاده از ابزارهای محبوب می‌پردازد.\n\nمنابع بیشتر\nبرای لیست کامل و بررسی دقیق‌تر بهترین کتاب‌های هوش مصنوعی، می‌توانید به بخش معرفی کتاب‌های هوش مصنوعی در مجله هوش مصنوعی سیمرغ مراجعه کنید.\n\nاخبار جعلی، دیپ فیک و امنیت سیاسی\nمفهومی به نام دیپ‌فیک (به انگلیسی: Deepfakes) به هوش‌های مصنوعی اطلاق می‌شود که قادر هستند چهره و صدای افراد را بازسازی و شبیه‌سازی نمایند. امروزه تشخیص نسخه‌های فیک و تقلبی از نسخه‌های اصلی کار بسیار مشکلی است.\nاین موضوع می‌تواند تهدیدی برای افراد مشهور اعم از هنرمندان، ورزشکاران و سیاست‌مداران باشد و زندگی حرفه‌ای آن‌ها را دچار خدشه و چالش نماید. بازسازی سخنرانی یک رئیس‌جمهور و درج موارد ناخواسته در میان آن یا بازسازی تصاویر سیاست‌مداران در یک فضای خاص می‌تواند نمونه‌ای از این موارد باشد.\nبه‌طورکلی هوش مصنوعی دیپ‌فیک، یک فناوری تغییر دهنده محتوا محسوب می‌شود. طبق گزارش ZDNet دیپ فیک «چیزی را ارائه می‌دهد که در واقع رخ نداده است». طبق این گزارش ۸۸٪ آمریکایی‌ها معتقدند دیپ فیک بیشتر از فایده باعث آسیب می‌شود اما تنها ۴۷٪ آنها معتقدند که ممکن است مورد هدف قرار گیرند. با اوج‌گیری رقابت‌های انتخاباتی شکل‌گیری فیلم‌های تبلیغاتی جعلی می‌تواند تهدیدی برای سیاست‌مداران محسوب شود.\n\nجستارهای وابسته\nیادداشت‌ها\nارجاعات\nمنابع\nکتب درسی AI\nاین کتب، پراستفاده‌ترین کتب درسی AI در ۲۰۰۷ میلادی بوده‌اند.\n\nدوتا از پراستفاده‌ترین کتب درسی در ۲۰۲۱ میلادی.[۱]\n\nدیگر منابع\n\nمنابع آزاد\n این مقاله دربردارنده متونی از اثر محتوای آزاد است لیسانس تحت C-BY-SA 3.0 IGO. نوشته گرفته شده از UNESCO Science Report: the Race Against Time for Smarter Development.,  Schneegans, S. , T. Straza and J. Lewis (eds), یونسکو. برای یادگیری در مورد چگونگی افزودن لیسانس باز متن به مقالات ویکی‌پدیا، لطفاً این صفحه را ببینید. برای اطلاع در مورد استفاده مجدد متون ویکی‌پدیا، لطفاً شرایط استفاده از آن را ببینید. \n\n\n== پیوند به بیرون =="
    },
    {
        "title": "یادگیری_ماشین",
        "text": "یادگیری ماشین (به انگلیسی: Machine learning) یا اِم‌اِل (اختصاری ML)، مطالعهٔ الگوریتم‌ها و مدل‌های آماری مورد استفادهٔ سیستم‌های کامپیوتری است که به‌جای استفاده از دستورالعمل‌های واضح، از الگوها و استنباط برای انجام وظایف استفاده می‌کنند. یادگیری ماشینی علمی است که باعث می‌شود رایانه‌ها بدون نیاز به یک برنامه صریح در مورد یک موضوع خاص یاد بگیرند. به عنوان زیر مجموعه‌ای از هوش مصنوعی، الگوریتم‌های یادگیری ماشینی یک مدل ریاضی بر اساس داده‌های نمونه یا داده‌های آموزش به منظور پیش‌بینی یا تصمیم‌گیری بدون برنامه‌ریزی آشکار، ایجاد می‌کنند.\nیادگیری ماشین در بسیاری زمینه‌ها از جمله مهندسی، کسب و کار، زبان‌شناسی و پزشکی کاربرد دارد. یادگیری ماشینی در بسیاری جنبه‌های زندگی روزمره وارد شده‌است. برای نمونه، موتورهای جستجوی اینترنتی در گوگل یا بینگ از یادگیری ماشینی استفاده می‌کنند، چرا که نرم‌افزار یادگیری ماشینی آن‌ها چگونگی رتبه‌بندی برای یک صفحه وب را درک کرده‌است. همین‌طور فیس‌بوک یا برنامه عکس اپل که تصاویر افراد را شناسایی می‌کند نوعی از یادگیری ماشینی است. فیلتر هرزنامه‌ها (spam) در ایمیل هم از کاربردهای یادگیری ماشینی است.\nبه بیانی دیگر از طریق «یادگیری ماشین»، سامانه‌هایی رایانه‌ای ساخته می‌شود که از داده‌هایی که دریافت می‌کنند، یادمی‌گیرند که چگونه وظایف خود را اجرا کنند؛ یعنی به جای آن که برنامه‌نویس و توسعه‌دهنده خط به خط دستورالعملی که یک برنامه کدنویسی شده باید انجام بدهد را مشخص کند، خود نرم‌افزار به‌طور مستقل کد خود را بعد از استفاده شدن به‌روز می‌کند و برای به دست آمدن نتیجهٔ بهتر، کد خود را بهبود می‌بخشد.\n\nهدف‌ها و انگیزه‌ها\nهدف یادگیری ماشینی این است که رایانه‌ها و سامانه‌ها بتوانند به تدریج و با افزایش داده‌ها کارایی بهتری در انجام وظیفهٔ مورد نظر پیدا کند.\nگسترهٔ این وظیفه می‌تواند از تشخیص خودکار چهره با دیدن چند نمونه از چهرهٔ مورد نظر تا فراگیری شیوهٔ گام‌برداری روبات‌های دوپا با دریافت سیگنال پاداش و تنبیه باشد.\nطیف پژوهش‌هایی که در یادگیری ماشینی می‌شود گسترده‌است.\nبه لحاظ نظری پژوهش‌گران بر آن‌اند که روش‌های یادگیری تازه‌ای به وجود بیاورند و امکان‌پذیری و کیفیت یادگیری را برای روش‌های‌شان مطالعه کنند و در سوی دیگر عده‌ای از پژوهش‌گران سعی می‌کنند روش‌های یادگیری ماشینی را بر مسایل تازه‌ای اعمال کنند. البته این طیف گسسته نیست و پژوهش‌های انجام‌شده دارای مؤلفه‌هایی از هر دو روی‌کرد هستند.\nیادگیری ماشینی کمک فراوانی به صرفه جویی در هزینه‌های عملیاتی و بهبود سرعت عمل تجزیه و تحلیل داده‌ها می‌کند. به عنوان مثال در صنعت نفت و پتروشیمی با استفاده از یادگیری ماشین، داده‌های عملیاتی تمام حفاری‌ها اندازه‌گیری شده و با تجزیه و تحلیل داده‌ها، الگوریتم‌هایی تنظیم می‌شود که در حفاری‌های بعدی استخراج پُربازده و بهینه‌تری داشته باشیم. در حقیقت یادگیری ماشین با نگاه به داده، پارادایم ویژه‌ای برای بررسی علوم محاسباتی ایجاد می‌کند.\n\nتقسیم‌بندی مسائل\nیکی از تقسیم‌بندی‌های متداول در یادگیری ماشین، تقسیم‌بندی بر اساس نوع داده‌های در اختیار کارگزار هوشمند است. به سناریوی زیر توجه کنید:\nفرض کنید به تازگی رباتی سگ‌نما خریده‌اید که می‌تواند توسط دوربینی دنیای خارج را مشاهده کند، به کمک میکروفن هایش صداها را بشنود، با  بلندگو هایی با شما سخن بگوید (گیریم محدود) و چهارپایه‌اش را حرکت دهد. همچنین در جعبهٔ این ربات دستگاه کنترل از راه دوری وجود دارد که می‌توانید انواع مختلف دستورها را به ربات بدهید. در پاراگراف‌های آینده با بعضی از نمونه‌های این دستورها آشنا خواهید شد.\nاولین کاری که می‌خواهید بکنید این است که اگر ربات شما را دید خرناسه بکشد اما اگر غریبه‌ای را مشاهده کرد با صدای بلند پارس(عوعو) کند. حال فرض می‌کنیم که ربات توانایی تولید آن صداها را دارد اما هنوز چهرهٔ شما را یادنگرفته‌است. پس کاری که می‌کنید این است که جلوی چشم‌های‌اش قرار می‌گیرید و به کمک کنترل از راه دورتان به او دستور می‌دهید که چهره‌ای که جلوی‌اش می‌بیند را با خرناسه‌کشیدن مربوط کند. این‌کار را برای چند زاویهٔ مختلف از صورت‌تان انجام می‌دهید تا مطمئن باشید که ربات در صورتی که شما را مثلاً از نیم‌رخ ببیند برای تان پارس نکند. همچنین شما چند چهرهٔ غریبه نیز به او نشان می‌دهید و چهرهٔ غریبه را با دستور پارس کردن مشخص می‌کنید. در این حالت شما به کامپیوتر ربات گفته‌اید که چه ورودی را به چه خروجی مربوط کند. دقت کنید که هم ورودی و هم خروجی مشخص است و در اصطلاح خروجی برچسب‌دار است. به این شیوهٔ یادگیری، یادگیری با نظارت می‌گویند.\nاینک حالت دیگری را فرض کنید. برخلاف دفعهٔ پیشین که به ربات‌تان می‌گفتید چه محرکه‌ای را به چه خروجی ربط دهد، این‌بار می‌خواهید ربات خودش چنین چیزی را یاد بگیرد. به این صورت که اگر شما را دید و خرناسه کشید به نحوی به او پاداش دهید (مثلاً با کمک همان کنترل از راه دورتان) و اگر به اشتباه به شما پارس کرد، او را تنبیه کنید (با کمک کنترل از راه دورتان). در این حالت به ربات نمی‌گویید به ازای هر شرایطی چه کاری مناسب است، بلکه اجازه می‌دهید ربات خود کاوش کند و تنها شما نتیجهٔ نهایی را تشویق یا تنبیه می‌کنید. به این شیوهٔ یادگیری، یادگیری تقویتی می‌گویند.\nدر دو حالت پیش قرار بود ربات ورودی را به خروجی مرتبط کند. اما گاهی وقت‌ها تنها می‌خواهیم ربات بتواند تشخیص دهد که آنچه می‌بیند (یا می‌شنود و…) را به نوعی به آنچه پیش‌تر دیده‌است ربط دهد بدون این‌که به‌طور مشخص بداند آن‌چیزی که دیده شده‌است چه چیزی است یا این‌که چه کاری در موقع دیدنش باید انجام دهد. ربات هوش‌مند شما باید بتواند بین صندلی و انسان تفاوت قایل شود بی‌آنکه به او بگوییم این نمونه‌ها صندلی‌اند و آن نمونه‌های دیگر انسان. در این‌جا برخلاف یادگیری با نظارت هدف ارتباط ورودی و خروجی نیست، بلکه تنها دسته‌بندی‌ی آن‌ها است. این نوع یادگیری که به آن یادگیری بی‌نظارت می‌گویند بسیار مهم است چون دنیای ربات پُر از ورودی‌هایی است که کسی برچسبی به آن‌ها اختصاص نداده اما به وضوح جزئی از یک دسته هستند.\nیادگیری بی‌نظارت را می‌توان به صورت عمل کاهش بعد در نظر گرفت.\nاز آن‌جا که شما سرتان شلوغ است، در نتیجه در روز فقط می‌توانید مدت محدودی با رباتتان بازی کنید و به او چیزها را نشان دهید و نام‌شان را بگویید (برچسب‌گذاری کنید). اما ربات در طول روز روشن است و داده‌های بسیاری را دریافت می‌کند. در این‌جا ربات می‌تواند هم به خودی خود و بدون نظارت یاد بگیرد و هم این‌که هنگامی که شما او را راهنمایی می‌کنید، سعی کند از آن تجارب شخصی‌اش استفاده کند و از آموزش شما بهرهٔ بیش‌تری ببرد. ترکیبی که عامل هوشمند هم از داده‌های بدون برچسب و هم از داده‌های با برچسب استفاده می‌کند به یادگیری نیمه نظارتی می‌گویند.\n\nیادگیری با نظارت\nیادگیری تحت نظارت، یک روش عمومی در یادگیری ماشینی است که در آن به یک سیستم، مجموعه‌ای از جفت‌های ورودی – خروجی ارائه شده و سیستم تلاش می‌کند تا تابعی از ورودی به خروجی را فرا گیرد. یادگیری تحت نظارت نیازمند تعدادی داده ورودی به منظور آموزش سیستم است. یادگیری تحت نظارت خود به دو دسته تقسیم می‌شود: رگرسیون و طبقه‌بندی. رگرسیون آن دسته از مسائل هستند که خروجی یک عدد پیوسته یا یک سری اعداد پیوسته هستند مانند پیش‌بینی قیمت خانه بر اساس اطلاعاتی مانند مساحت، تعداد اتاق خواب‌ها، و غیره و دسته طبقه‌بندی به آن دسته از مسائل گفته می‌شود که خروجی یک عضو از یک مجموعه باشد مانند پیش‌بینی اینکه یک ایمیل هرزنامه هست یا خیر یا پیش‌بینی نوع بیماری یک فرد از میان ۱۰ بیماری از پیش تعریف شده. با این حال رده‌ای از مسائل وجود دارند که خروجی مناسب که یک سیستم یادگیری تحت نظارت نیازمند آن است، برای آن‌ها موجود نیست. این نوع از مسائل چندان قابل جوابگویی با استفاده از یادگیری تحت نظارت نیستند. یادگیری تقویتی مدلی برای مسائلی از این قبیل فراهم می‌آورد. در یادگیری تقویتی، سیستم تلاش می‌کند تا تقلب های خود را ،با یک محیط پویا از طریق آزمون و خطا بهینه سازد. یادگیری تقویتی مسئله‌ای است که یک عامل که می‌بایست رفتار خود را از طریق تعاملات آزمون و خطا با یک محیط پویا فرا گیرد، با آن مواجه است. در یادگیری تقویتی هیچ نوع زوج ورودی – خروجی ارائه نمی‌شود. به جای آن، پس از اتخاذ یک عمل، حالت بعدی و پاداش بلافصل به عامل ارائه می‌شود. هدف اولیه برنامه‌ریزی عامل‌ها با استفاده از تنبیه و تشویق است بدون آنکه ذکری از چگونگی انجام وظیفه آن‌ها شود.\n\nیادگیری با نظارت آماری\nدر آمار احتمال خروجی بر حسب ورودی محاسبه می‌شود. اگر ورودی \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \nباشد و خروجی \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n،\n  \n    \n      \n        p\n        (\n        y\n        \n          |\n        \n        x\n        )\n      \n    \n    {\\displaystyle p(y|x)}\n  \n از داده‌ها یادگرفته می‌شود، به عبارت دیگر یادگیری در واقع پیدا کردن تابع \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \nاست. دو روش کلی برای پیدا کردن تابع \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n وجود دارد: روش تولیدی (Generative) و روش تشخیصی (Discriminative). به بیان بسیار ساده، در روش تشخیصی، ماشین مرز بین طبقه‌های مختلف را یادمی‌گیرد، اما در روش تولیدی، ماشین نحوهٔ تولید نمونه‌های یک طبقه را یادمی‌گیرد. به بیان ریاضی، در روش تشخیصی \n  \n    \n      \n        p\n        (\n        y\n        \n          |\n        \n        x\n        )\n      \n    \n    {\\displaystyle p(y|x)}\n  \n مستقیماً یادگرفته می‌شود، ولی در روش تولیدی ابتدا \n  \n    \n      \n        p\n        (\n        y\n        )\n      \n    \n    {\\displaystyle p(y)}\n  \n و \n  \n    \n      \n        p\n        (\n        x\n        \n          |\n        \n        y\n        )\n      \n    \n    {\\displaystyle p(x|y)}\n  \n از داده‌ها برآورد می‌شوند و بعد با استفاده از قانون بیز (Bayes) \n  \n    \n      \n        p\n        (\n        y\n        \n          |\n        \n        x\n        )\n      \n    \n    {\\displaystyle p(y|x)}\n  \n محاسبه می‌شود.\n\nتعریف ریاضی یادگیری با نظارت\nدر یادگیری با نظارت، مثال‌های آموزشی به صورت جفت‌های (\n  \n    \n      \n        \n          x\n          \n            i\n          \n        \n        ,\n        \n          y\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle x^{i},y^{i}}\n  \n) که در آن هر نمونه به همراه بر چسب آن داده شده‌اند و \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n اندیس هر مثال در مجموعه مثال‌های آموزشی \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \nاست. هدف در این یادگیری به‌دست آوردن تابع \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n است که بتواند برای نمونه‌های ورودی دیده نشده \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \nبر چسب مناسب را برگرداند یعنی \n  \n    \n      \n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(x)}\n  \n را. نمونه و برچسب هر دو می‌توانند یک بردار باشند. اگر برچسب یک عدد حقیقی باشد مسئله پیش روی ما «رگرسیون» (Regression) نامیده می‌شود. اگر برچسب یک عدد صحیح باشد به مسئله «طبقه‌بندی» (Classification) گفته می‌شود.\n\nیادگیری بی‌نظارت\nیادگیری بی‌نظارت یا یادگیری بدون نظارت (انگلیسی: Unsupervised Learning، در مقابل یادگیری بانظارت)، یکی از انواع یادگیری در یادگیری ماشین است. اگر یادگیری بر روی داده‌های بدون برچسب و برای یافتن الگوهای پنهان در این داده‌ها انجام شود، یادگیری بدون نظارت خواهد بود. از انواع یادگیری بدون نظارت می‌توان به الگوریتم‌های خوشه‌بندی (Clustering)، تخصیص پنهان دیریکله (LDA) و جاسازی لغات (Word Embedding) اشاره کرد.\n\nمثالی از یادگیری بی‌نظارت\nاز یادگیری نظارت نشده در دنیای امروز می‌توان مثال‌های متعددی زد. یکی از پُرکاربردترین آن‌ها پیشنهادهایی است که به کاربران در شبکه‌های اجتماعی داده می‌شود. به عنوان مثال در اینستاگرام داده‌های زیادی از هر کاربر از جمله علایق شخصی، کسانی که دنبال می‌کند، دنبال‌کنندگان او وجود دارد. اینستاگرام براساس این داده‌ها، ویژگی‌های کابران را تعیین کرده و آن‌ها را خوشه‌بندی می‌کند. در نهایت با توجه به خوشه‌ای که کاربر درون آن قرار گرفته‌است، پیشنهادهای متعددی به وی به منظور درگیر کردن بیشتر او با این شبکه اجتماعی می‌دهد.\n\nیادگیری تقویتی\nهدف یادگیری تقویتی که بخش دیگری از یادگیری ماشینی است این است که چگونه عامل‌های نرم‌افزاری، باید یک عمل را مناسب محیط انتخاب کنند تا پاداش بهینه بیشینه شود. این رشته به دلیل کلی بودن، در بسیاری از رشته‌های دیگر از جمله نظریه بازی، تئوری کنترل، تحقیق در عملیات، تئوری اطلاعات، بهینه‌سازی مبتنی بر شبیه‌سازی، سیستم‌های چند عامل، هوشمند جمعی، آمار و الگوریتم‌های ژنتیکی مورد مطالعه قرار می‌گیرد. در یادگیری ماشین، محیط به‌طور معمول به عنوان یک فرایند تصمیم‌گیری مارکوف (MDP) معرفی می‌شود. بسیاری از الگوریتم‌های یادگیری تقویتی از تکنیک‌های برنامه‌نویسی پویا استفاده می‌کنند. در الگوریتم‌های یادگیری تقویتی، فرضیه مبتنی بر دانش یک مدل دقیق ریاضی از MDP نیست، و هنگامی که مدل‌های دقیق غیرقابل دسترسی هستند مورد استفاده قرار می‌گیرد. الگوریتم‌های یادگیری تقویتی در وسایل نقلیه خودران یا در یادگیری بازی در برابر حریف انسانی استفاده می‌شود.\n\nیادگیری دیکشنری پراکنده\nیادگیری دیکشنری پراکنده یا فرهنگ لغت پراکنده یک روش یادگیری است که در آن یک مثال آموزشی به عنوان ترکیبی خطی از توابع پایه ارائه می‌شود، و فرض بر این است که یک ماتریس پراکنده‌است. این مسئله از نوع به شدت سخت NP-hard است و حل تقریبی آن دشوار است. الگوریتم K-SVD یک روش اکتشافی معمول برای یادگیری دیکشنری پراکنده‌است. یادگیری دیکشنری پراکنده در چندین زمینه استفاده شده‌است. در دسته‌بندی، مسئله مشخص کردن کلاس‌هایی است که قبلاً دیده نشده‌اند متعلق به نمونه آموزشی اند. برای دیکشنری که در آن هر کلاس از قبل ساخته شده‌است، یک مثال آموزشی جدید با کلاس همراه است که به بهترین شکل توسط دیکشنری مربوط نمایش داده می‌شود؛ مثلاً یادگیری دیکشنری پراکنده در تشخیص و جداسازی نویز تصویر استفاده شده‌است. ایده اصلی این است که تکه‌های تصویر تمیز و بدون نویز می‌تواند جداگانه توسط یک دیکشنری تصویری نشان داده شود، اما قسمت نویز نمی‌تواند.\n\nروش‌های جدید یادگیری ماشینی\nماشین سازنده متغیر همبسته بالا (HCVCM)\nاین الگوریتم یک مدل ترکیبی جدید برای بهبود مدلهای رگرسیون و مدلهای شبکه عصبی مصنوعی برای پیش‌بینی پدیده‌ها و عملکرد مواد است. ماشین سازنده متغیر همبسته بالا (HCVCM) سعی دارد متغیرهای جدیدی را به جای متغیرهای اولیه ایجاد کند که در بهبود دقت مدل‌ها موثرتر هستند. این متغیرها از متغیرهای اولیه با استفاده از توابع ریاضی متغیرهای جدیدی ایجاد می‌کند، به گونه ای که ارتباط بیشتری با خروجی و همبستگی کمتری با ورودی‌های دیگر دارند. در HCVCM سه مرحله وجود دارد. یکم ،با استفاده از چندین توابع ریاضی متغیرهای جدیدی ایجاد می‌کنند. سپس متغیرهای جدید انتخاب می‌شوند، که در مقایسه با متغیرهای اولیه ضریب همبستگی بیشتری با خروجی دارند. در مرحله سوم فقط متغیرهای جدیدی انتخاب می‌شوند که همبستگی آن‌ها کمتر از همبستگی بین متغیرهای اولیه است. این روش در سال ۲۰۲۰ توسط آیدین شیشه‌گران ارائه شد.\n\nماشین خالق متغیر قوی‌تر (SVCM)و ماشین انتخابگر پویا (DSM)\nشیشه‌گران و همکارانش روش‌های جدید مختلفی  را برای توسعه روش‌های یادگیری ماشین ایجاد کردند، مانند ماشین خالق متغیر قوی‌تر (SVCM) و ماشین انتخاب پویا (DSM) که می‌تواند به صورت پویا از بین چندین ماشین انتخاب کند که یکی از آنها برای هر مجموعه داده و متغیرهای ورودی دقیق تر است. به عبارت دیگر، او مدلی را در سال 2023 ایجاد کرد که می تواند مدل دقیق بین ماشین های مختلف را بر اساس ویژگی پارامترهای ورودی پیش بینی کند. کارشناسان معتقدند که DSM می تواند انقلابی در روش های یادگیری ماشینی باشد، زیرا این روش هوش مصنوعی می تواند ماشین های دیگر را مدیریت کند.\n\nبهترین زبان‌های برنامه‌نویسی برای یادگیری ماشینی\nامروزه با توجه به گستردگی زبان‌های برنامه‌نویسی، علاقه‌مندان به این بخش از هوش مصنوعی ،از زبان‌های مختلفی استفاده می‌کنند. پُراستفاده‌ترین این زبان‌ها عبارتند از:\n\nپایتون\nمتلب\nجاوا\nآر\nجاوا اسکریپت\nسی‌شارپ\nاسکالا\n\nبهترین زبان برنامه‌نویسی برای یادگیری ماشینی\nنکته‌ای که باید در نظر داشت این است که بهترین زبان برنامه‌نویسی برای هوش مصنوعی و یادگیری ماشینی وجود ندارد. چرا که این مسئله کاملاً وابسته به موردی است که برنامه‌نویس می‌خواهد برای آن موضوع کدنویسی کند. به‌عنوان مثال فردی تنها می‌خواهد مفاهیم اولیه یادگیری ماشینی را فراگیرد. برای چنین شخصی استفاده از یک زبان برنامه‌نویسی با محیط قابل فهم و آسان کفایت می‌کند.\nممکن است فرد دیگری در فرایند یادگیری ماشینی نیاز به پردازش تصویری داشته باشد. در چنین حالتی زبان‌های متلب و پایتون بهترین گزینه هستند. چرا که کتابخانه‌های قوی برای پردازش تصویر دارند. در حالتی که افراد بخواهند در تئوری‌های مربوط به یادگیری ماشینی عمیق شده و از روش‌های آماری خاص استفاده کنند گزینه مناسب R خواهد بود. البته سی شارپ که به تازگی با ارائه عمومی مدل بیلدر وارد این مبحث شده (قبل از این هم از مدل بیلدر در برخی فناوری‌های خود مانند bing استفاده کرده بود) قطعاً حرف‌های زیادی در این زمینه خواهد داشت. همچنین با توجه به سادگی استفاده از آن و تنها با تسلط به زبان #C و حتی با دانش اندک ریاضی محبوبیت خود را به دست می‌آورد.\n\nمراحل یادگیری ماشین\nفرایند یادگیری ماشین در مراحل مختلفی اتفاق می‌افتد که در ادامه به آنها اشاره می‌کنیم و هر کدام از مراحل را بررسی می‌کنیم.\nجمع آوری و کار با داده‌ها :\nاساس کار یادگیری ماشین با داده‌هاست و داده‌های مناسب و نرمال شده یکی از مهم‌ترین قسمت‌های فرایند یادگیری است. در این مرحله داده‌های مربوط به مدل یادگیری ماشین جمع‌آوری شده و به روش‌های مختلف تبدیل به داده‌های آماده پردازش می‌شوند و یا به اصطلاح نرمالایز می‌شوند. داده‌ها به دو بخش داده‌های آموزشی و داده‌های تستی تقسیم می‌شوند. از داده‌های آموزشی برای آموزش مدل و از داده‌های تستی برای تست عملکرد مدل پس از آموزش استفاده می‌شود.\nانتخاب الگوریتم و مدل مناسب و آموزش :\nمرحله بعدی استفاده از یک مدل مناسب برای آموزش، با داده‌های موجود است. الگوریتم و مدل‌های از قبل طراحی شده‌ای وجود دارد که شما می‌توانید متناسب با نیاز خود یکی از آنها و یا ترکیبی از چند مدل را برای آموزش انتخاب کنید. در این مرحله داده‌هایی که برای آموزش مدل در نظر گرفته شده بودند به مدل داده می‌شود و مدل شروع به آموزش از روی آن داده‌ها می‌کند.\nاعتبارسنجی :\nپس از مرحله انتخاب مدل و آموزش آن، نوبت به اعتبارسنجی می‌رسد. در این مرحله با استفاده از متدهای مختلف شروع به اعتبارسنجی مدل می‌شود. اعتبارسنجی مدل با استفاده از داده‌هایی که برای تست در نظر گرفته شده انجام می‌شود. مدل پس از آموزش با داده‌های تست اعتبارسنجی می‌شود تا مشخص شود میزان خطا و یا درستی مدل چقدر است. در این مرحله با توجه به جواب به دست آمده هایپر پارامترها تنظیم می‌شوند.\n\nجستارهای وابسته\nیادگیری عمیق\nیادگیری تقویتی\nعلم داده‌ها\nالگوریتم فرگشتی\nالگوریتم ژنتیک\nشبکه عصبی مصنوعی\nهوش جامع مصنوعی\n\nپانویس\nمنابع\nنگاهی آماری به یادگیری ماشینی و به‌طور خاص یادگیری ماشینی با نظارت.\n ‏\n\nمرجعی ساده و روان برای یادگیری تقویتی؛ مناسب برای یادگیری اصول اولیه:\nآکادمی داده‌کاوی\nاین کتاب کم حجم یکی از عمده‌ترین مراجع کلاسیک در زمینهٔ یادگیری ماشینی است:"
    },
    {
        "title": "پردازش_زبان‌های_طبیعی",
        "text": "پردازش زبان‌های طبیعی یکی از زیرشاخه‌های مهم در حوزهٔ علوم رایانه، هوش مصنوعی است که به تعامل بین کامپیوتر و زبان‌های (طبیعی) انسانی می‌پردازد؛ بنابر این پردازش زبان‌های طبیعی بر ارتباط انسان و رایانه، متمرکز است. چالش اصلی و عمده در این زمینه، درک زبان طبیعی و ماشینی کردن فرایند درک و برداشت مفاهیم بیان‌شده با یک زبان طبیعیِ انسانی است. به تعریف دقیق‌تر، پردازش زبان‌های طبیعی عبارت است از استفاده از رایانه برای پردازش زبان گفتاری و زبان نوشتاری. بدین معنی که رایانه‌ها را قادر سازیم که گفتار یا نوشتار تولید شده در قالب و ساختار یک زبان طبیعی را تحلیل و درک نموده یا آن را تولید نمایند. در این صورت، با استفاده از آن می‌توان به ترجمهٔ زبان‌ها پرداخت، از صفحات وب و بانک‌های اطلاعاتیِ نوشتاری جهت پاسخ دادن به پرسش‌ها استفاده کرد، یا با دستگاه‌ها، مثلاً برای مشورت گرفتن به گفت‌وگو پرداخت.این‌ها تنها مثال‌هایی از کاربردهای متنوع پردازش زبان‌های طبیعی هستند.\nهدف اصلی در پردازش زبان طبیعی، ساخت تئوری‌هایی محاسباتی از زبان، با استفاده از الگوریتم‌ها و ساختارهای داده‌ای موجود در علوم رایانه است. بدیهی است که در راستای تحقق این هدف، نیاز به دانشی وسیع از زبان است و علاوه بر محققان علوم رایانه، نیاز به دانش زبان شناسان نیز در این حوزه می‌باشد. با پردازش اطلاعات زبانی می‌توان آمار مورد نیاز برای کار با زبان طبیعی را استخراج کرد.\nکاربردهای پردازش زبان طبیعی به دو دسته کلی قابل تقسیم است: کاربردهای نوشتاری و کاربردهای گفتاری.\n\nاز کاربردهای نوشتاری آن می‌توان به استخراج اطلاعاتی خاص از یک متن، ترجمه یک متن به زبانی دیگر یا یافتن مستنداتی خاص در یک پایگاه داده نوشتاری (مثلاً یافتن کتاب‌های مرتبط به هم در یک کتابخانه) اشاره کرد.\nنمونه‌هایی از کاربردهای گفتاری پردازش زبان عبارتند از: سیستم‌های پرسش و پاسخ انسان با رایانه، سرویس‌های اتوماتیک ارتباط با مشتری از طریق تلفن، سیستم‌های آموزش به فراگیران یا سیستم‌های کنترلی توسط صدا که در سالهای اخیر این حوزه تحقیقاتی توجه دانشمندان را به خود جلب کرده‌است و تحقیقات قابل ملاحظه‌ای در این زمینه صورت گرفته‌است.\n\nتاریخچه\nبه‌طور کلی تاریخچه پردازش زبان طبیعی از دهه ۱۹۵۰ میلادی شروع می‌شود. در ۱۹۵۰ آلن تورینگ مقاله معروف خود را دربارهٔ آزمایش تورینگ که امروزه به عنوان ملاک هوشمندی شناخته می‌شود، منتشر ساخت.\nنخستین تلاش‌ها برای ترجمه توسط رایانه ناموفق بودند، به‌طوری‌که ناامیدی بنگاه‌های تأمین بودجهٔ پژوهش از این حوزه را نیز در پی داشتند. پس از اولین تلاش‌ها آشکار شد که پیچیدگی زبان بسیار بیشتر از چیزی‌ست که پژوهشگران در ابتدا پنداشته‌بودند. بی‌گمان حوزه‌ای که پس از آن برای استعانت مورد توجه قرار گرفت زبان‌شناسی بود. اما در آن دوران نظریهٔ زبان‌شناسی وجود نداشت که بتواند کمک شایانی به پردازش زبان‌ها بکند. در سال ۱۹۵۷ کتاب ساختارهای نحوی اثر نوام چامسکی زبان‌شناس جوان آمریکایی که از آن پس به شناخته‌شده‌ترین چهرهٔ زبان‌شناسی نظری تبدیل شد به چاپ رسید. از آن پس پردازش زبان با حرکت‌های تازه‌ای دنبال شد اما هرگز قادر به حل کلی مسئله نشد.\nNLP مبتنی بر قوانین دست‌نویس (دهه ۱۹۵۰ - اوایل دهه ۱۹۹۰)\n\nدهه ۱۹۵۰: آزمایش جورج تاون در سال ۱۹۵۴ شامل ترجمه کاملاً خودکار بیش از شصت جمله روسی به انگلیسی بود. نویسندگان ادعا کردند که ظرف سه یا پنج سال، ترجمه ماشینی یک مشکل حل شده خواهد بود. با این حال، پیشرفت واقعی بسیار کندتر بود، و پس از گزارش ALPAC در سال ۱۹۶۶، که نشان می‌داد تحقیقات ده ساله نتوانسته‌است انتظارات را برآورده کند، بودجه برای ترجمه ماشینی به‌طور چشمگیری کاهش یافت. تحقیقات کمی در مورد ترجمه ماشینی در آمریکا انجام شد (اگرچه برخی از تحقیقات در جاهای دیگر مانند ژاپن و اروپا) تا اواخر دهه ۱۹۸۰ که اولین سیستم‌های ترجمه ماشینی آماری توسعه یافتند، ادامه یافت.\nدهه ۱۹۶۰: برخی از سیستم‌های پردازش زبان طبیعی موفق که در دهه ۱۹۶۰ توسعه یافتند عبارت بودند از SHRDLU، یک سیستم زبان طبیعی که در «جهان‌های بلوکی» محدود با واژگان محدود کار می‌کرد، و ELIZA، شبیه‌سازی یک روان‌درمانگر بود، که توسط جوزف وایزنبام بین سال‌های ۱۹۶۴ و ۱۹۶۶ نوشته شده بود. الایزا با استفاده از تقریباً هیچ اطلاعاتی در مورد افکار یا احساسات انسان، گاهی تعامل شگفت‌انگیزی شبیه انسان ارائه می‌داد. ولی وقتی \"بیمار\" از پایگاه دانش بسیار کوچک فراتر می‌رفت، ELIZA ممکن بود یک پاسخ عمومی ارائه دهد، برای مثال، به \"سرم درد می‌کند\" با \"چرا می‌گویی سرت درد می‌کند؟\" پاسخ دهد.\nدهه ۱۹۷۰: در طول دهه ۱۹۷۰، بسیاری از برنامه نویسان شروع به نوشتن «هستی‌شناسی‌های مفهومی» کردند، که اطلاعات دنیای واقعی را به داده‌های قابل فهم کامپیوتری ساختار می‌داد. در طول این مدت، اولین ربات‌های گفتگو (به عنوان مثال، PARRY) نوشته شدند.\nدهه ۱۹۸۰: دهه ۱۹۸۰ و اوایل دهه ۱۹۹۰ دوران اوج روش‌های دست‌نویس در NLP است. حوزه‌های مورد توجه در آن زمان شامل تحقیق در مورد تجزیه مبتنی بر قاعده(rule-based parsing) (مانند توسعه HPSG به عنوان عملیاتی محاسباتی گرامر مولد)، مورفولوژی (مانند مورفولوژی دو سطحی)، معناشناسی (مانند الگوریتم Lesk) بودند.\nNLP مبتنی بر روشهای آماری (۱۹۹۰–۲۰۱۰)\nتا دهه ۱۹۸۰، اکثر سیستم‌های پردازش زبان طبیعی بر اساس مجموعه‌های پیچیده‌ای از قوانین دست نوشته بودند. از اواخر دهه ۱۹۸۰، با معرفی الگوریتم‌های یادگیری ماشینی برای پردازش زبان، انقلابی در پردازش زبان طبیعی رخ داد. این امر هم به دلیل افزایش مداوم در قدرت محاسباتی و هم کاهش تدریجی تسلط نظریات زبان‌شناسی چامسکی بود.\n\nدهه ۱۹۹۰: بسیاری از موفقیت‌های اولیه قابل توجه در روش‌های آماری در NLP در زمینه ترجمه ماشینی رخ داد، به‌ویژه به دلیل تحقیقات IBM، مانند مدل‌های هم‌ترازی IBM. این سیستم‌ها می‌توانستند از مجموعه‌های(corpora) متنی چندزبانه موجود که توسط پارلمان کانادا و اتحادیه اروپا تهیه شده بود استفاده کنند. این مجموعه‌های متنی در نتیجه قوانینی که خواستار ترجمه تمام اقدامات دولتی به همه زبان‌های رسمی نظام‌های دولتی مربوطه بودند، تهیه شده بود. با این حال، بیشتر سیستم‌ها به مجموعه‌هایی وابسته بودند که به‌طور خاص برای وظایف پیاده‌سازی شده توسط این سیستم‌ها توسعه یافته بودند، که یک محدودیت عمده در موفقیت این سیستم‌ها بود. در نتیجه، تحقیقات زیادی روی روش‌های یادگیری مؤثرتر از مقادیر محدود داده انجام شد.\nدهه ۲۰۰۰: با رشد وب، از اواسط دهه ۱۹۹۰، مقدار فزاینده ای از داده‌های خام در دسترس قرار گرفت؛ بنابراین تحقیقات به‌طور فزاینده ای بر روی الگوریتم‌های یادگیری بدون نظارت و نیمه نظارتی متمرکز شد. چنین الگوریتم‌هایی می‌توانستند از داده‌هایی که به صورت دستی با پاسخ‌های مورد نظر یا با استفاده از ترکیبی از داده‌های بدون برچسب(unannotated) بیاموزند. به‌طور کلی، این کار بسیار دشوارتر از یادگیری تحت نظارت است و معمولاً نتایج دقیق کمتری را برای مقدار معینی از داده‌های ورودی ایجاد می‌کند. با این حال، حجم عظیمی از داده‌های بدون برچسب در دسترس است (از جمله، کل محتوای شبکه جهانی وب)، که اگر الگوریتم مورد استفاده پیچیدگی زمانی کافی داشته باشد، اغلب می‌تواند نتایج ضعیف‌تر را جبران کند.\nNLP مبتنی بر شبکه‌های عصبی (در حال حاضر)\nدر دهه ۲۰۱۰، روش‌های یادگیری بازنمایی و یادگیری ماشینی به سبک شبکه عصبی عمیق در پردازش زبان طبیعی رایج شد. این محبوبیت تا حدی به دلیل انبوهی از نتایج بود که نشان می‌داد چنین تکنیک‌هایی می‌توانند به نتایج پیشرفته‌ای در بسیاری از کارهای زبان طبیعی، مانند مدل‌سازی زبان و تجزیه دست یابند. این امر به‌طور فزاینده ای در پزشکی و مراقبت‌های بهداشتی مهم است.\n\nروشها: قوانین، آمارها، شبکه‌های عصبی\nدر ابتدا، بسیاری از سیستم‌های پردازش زبان با قوانین دست‌نویس، یعنی کدگذاری دستی مجموعه‌ای از قوانین، همراه با جستجوی فرهنگ لغت، طراحی می‌شدند: مانند نوشتن دستور زبان یا ابداع قوانین اکتشافی برای به دست آوردن ریشه واژه.\nولی سیستم‌های جدیدتر مبتنی بر الگوریتم‌های یادگیری ماشینی مزایای زیادی نسبت به قوانین دست‌ساز دارند:\n\nرویه‌های یادگیری مورد استفاده در طول یادگیری ماشینی به‌طور خودکار روی رایج‌ترین موارد تمرکز می‌کنند، در حالی که هنگام نوشتن قوانین با دست، اغلب مشخص نیست که تلاش باید به کجا هدایت شود.\nروش‌های یادگیری خودکار می‌توانند از الگوریتم‌های استنتاج آماری برای تولید مدل‌هایی استفاده کنند که برای ورودی‌های ناآشنا (مانند ورودی‌هایی که حاوی کلمات یا ساختارهایی هستند که قبلاً دیده نشده‌اند) و برای ورودی‌های اشتباه (مثلاً کلماتی که املایی ندارند یا کلماتی که تصادفاً حذف شده‌اند) بهتر عمل می‌کنند. به‌طور کلی، رسیدگی به چنین ورودی‌ها با قوانین دست‌نویس بسیار دشوار، مستعد خطا و زمان بر است.\nسیستم‌های مبتنی بر یادگیری خودکار قوانین را می‌توان به سادگی با ارائه داده‌های ورودی بیشتر دقیق تر کرد. با این حال، سیستم‌های مبتنی بر قوانین دست‌نویس تنها با افزایش پیچیدگی قوانین، که کار بسیار دشوارتری است، دقیق‌تر می‌شوند. درحالی که ایجاد داده‌های بیشتر برای ورودی به سیستم‌های یادگیری ماشینی صرفاً مستلزم افزایش ساعت‌های کار شده‌است و معمولاً بدون افزایش قابل توجهی در پیچیدگی فرایند برچسب نویسی می‌باشد.\nبا وجود محبوبیت یادگیری ماشینی در تحقیقات NLP، روش‌های دست‌نویس هنوز (۲۰۲۰) در موارد زیر استفاده می‌شوند:\n\nهنگامی که مقدار داده‌های آموزشی برای به‌کارگیری موفقیت‌آمیز روش‌های یادگیری ماشین کافی نیست، به عنوان مثال، برای ترجمه ماشینی زبان‌های کم منبع\nبرای پیش پردازش در NLP، مانند توکن سازی\nبرای پس پردازش و تبدیل خروجی NLP، به عنوان مثال برای استخراج دانش از تجزیه نحوی.\n\nروش‌های آماری\nاز زمان به اصطلاح «انقلاب آماری» در اواخر دهه ۱۹۸۰ و اواسط دهه ۱۹۹۰، بسیاری از تحقیقات پردازش زبان طبیعی به شدت بر یادگیری ماشین تکیه کردند.\nبسیاری از کلاس‌های مختلف الگوریتم‌های یادگیری ماشین برای وظایف پردازش زبان طبیعی به کار گرفته شده‌اند. این الگوریتم‌ها مجموعه بزرگی از «ویژگی‌ها» را که از داده‌های ورودی تولید می‌شوند، به عنوان ورودی می‌گیرند. با این حال، تحقیقات به‌طور فزاینده‌ای بر مدل‌های آماری متمرکز شده‌است، که تصمیم‌های نرم و احتمالی را بر اساس ضمیمه کردن وزن‌های با ارزش واقعی به هر ویژگی ورودی می‌گیرند. چنین مدل‌هایی این مزیت را دارند که می‌توانند قطعیت نسبی بسیاری از پاسخ‌های ممکن مختلف را به جای یک پاسخ بیان کنند، و زمانی که چنین مدلی به عنوان جزئی از یک سیستم بزرگ‌تر گنجانده شود، نتایج قابل اعتمادتری تولید می‌کند.\nبرخی از اولین الگوریتم‌های یادگیری ماشینی مورد استفاده، مانند درخت‌های تصمیم، سیستم‌هایی از قواعد سخت «اگر-آنگاه» مشابه قوانین دست‌نویس موجود تولید کردند. همچنین برچسب‌گذاری بخشی از گفتار، استفاده از مدل‌های پنهان مارکوف را در پردازش زبان طبیعی را معرفی کرد، و به‌طور فزاینده‌ای، تحقیقات بر روی مدل‌های آماری متمرکز شده‌اند که تصمیم‌های احتمالی را بر اساس ضمیمه کردن وزن‌های با ارزش واقعی به ویژگی‌های تشکیل‌دهنده ورودی می‌گیرند. مدل‌های زبان حافظه پنهان که اکنون بسیاری از سیستم‌های تشخیص گفتار بر آن‌ها تکیه دارند، نمونه‌هایی از این مدل‌های آماری هستند. چنین مدل‌هایی معمولاً وقتی ورودی ناآشنا به آنها داده می‌شود، به ویژه ورودی‌هایی که حاوی خطا هستند (همان‌طور که برای داده‌های دنیای واقعی بسیار رایج است)، بهتر عمل می‌کنند و زمانی که در یک سیستم بزرگ‌تر شامل وظایف فرعی متعدد ادغام می‌شوند، نتایج قابل اعتمادتری تولید می‌کنند.\nاز زمان روی آوردن به شبکه‌های عصبی، روش‌های آماری در تحقیقات NLP تا حد زیادی با شبکه‌های عصبی جایگزین شده‌اند. با این حال، آنها همچنان برای زمینه‌هایی که در آن‌ها قابلیت تفسیر و شفافیت آماری مورد نیاز است، استفاده می‌شوند.\n\nشبکه‌های عصبی\nیک اشکال عمده روش‌های آماری این است که آنها به مهندسی ویژگیها نیاز دارند. به همین علت از سال ۲۰۱۵ تحقیقات با روش‌های آماری تا حد زیادی رها شده و به سمت شبکه‌های عصبی برای یادگیری ماشین رفته‌است. تکنیک‌های رایج عبارتند از استفاده از جاسازی کلمات برای دریافت ویژگی‌های معنایی کلمات، و افزایش یادگیری تمام کار در سطح بالاتر (مثلاً پاسخ‌گویی به سؤال) به‌جای تکیه بر یک صف از وظایف میانی جداگانه (مثلاً، برچسب گذاری بخشی از گفتار و تجزیه وابستگی). در برخی زمینه‌ها، این تغییر مستلزم تغییرات اساسی در نحوه طراحی سیستم‌های NLP است، به طوری که رویکردهای مبتنی بر شبکه عصبی عمیق ممکن است به عنوان یک الگوی جدید متمایز از پردازش زبان طبیعی آماری در نظر گرفته شوند. به عنوان مثال، اصطلاح ترجمه ماشینی عصبی (NMT) بر این واقعیت تأکید دارد که رویکردهای مبتنی بر یادگیری عمیق برای ترجمه ماشینی مستقیماً از تبدیل‌های دنباله به دنباله یادمی‌گیرند، و نیاز به مراحل میانی مانند تراز کردن کلمات و مدل‌سازی زبان را که در آمار مورد استفاده قرار می‌گرفت، نیست.\n\nمحدودیت‌ها\nپردازش زبان‌های طبیعی رهیافت بسیار جذابی برای ارتباط بین انسان و ماشین محسوب می‌شود و در صورت عملی شدنش به‌طور کامل می‌تواند تحولات شگفت‌انگیزی را در پی داشته‌باشد. سیستم‌های قدیمی محدودی مانند SHRDLU که با واژه‌های محدود و مشخصی سر و کار داشتند، بسیار عالی عمل می‌کردند، به‌طوری‌که پژوهشگران را به شدت نسبت به این حوزه امیدوار کرده‌بودند. اما در تقابل با چالش‌های جدی‌تر زبانی و پیچیدگی‌ها و ابهام‌های زبان‌ها، این امیدها کم‌رنگ شدند.\nمسئلهٔ پردازش زبان‌های طبیعی معمولاً یک مسئلهٔ AI-complete محسوب می‌شود، چرا که محقق شدن آن به‌طور کامل مستلزم سطح بالایی از درک جهان خارج و حالات انسان برای ماشین است.\n\nمزایا و معایب NLP\nبا روی کار آمدن پردازش زبان طبیعی و همه‌گیر شدن استفاده از آن، سرعت انجام بسیاری از کارها که شاید روزانه زمان زیادی برای انجام آنها صرف می‌شد کاهش یافت. لذا صرفه جویی در زمان را شاید بتوان یکی از مهم‌ترین ویژگی‌های پردازش زبان طبیعی به حساب آورد. از طرفی راحتی در ایجاد ارتباط با ماشین‌ها به صورت صوتی یکی از ویژگی‌هایی است که افراد را بیشتر به استفاده از این تکنولوژی سوق می‌دهد. لذا به عنوان دومین مزیت می‌توان سهولت بخشیدن ارتباط بین انسان و ماشین را در نظر گرفت. دسترسی آسان هم یکی دیگر از خوبی‌های پردازش زبان طبیعی است. امروزه همه افراد از گوشی‌های تلفن هوشمند استفاده می‌کنند و گوشی‌های تلفن هم عمداً مجهز به این تکنولوژی هستند، لذا شما با همان گوشی تلفنی که کارهای روزمره خود را انجام می‌دهید، می‌توانید به کمک پردازش زبان طبیعی برخی امورات خود را به صورت صوتی هم انجام دهید. از طرفی باید در نظر داشته باشیم که تکنولوژی‌های بر مبنای پردازش زبان طبیعی کاستی ها و ایراداتی هم دارند که انتظار می‌رود به‌ مرور زمان برطرف شود. اشتباه در تشخیص کلمات و معانی آنها، برخی خطاهای پردازشی و عدم انعطاف پذیری در تشخیص صوت شاید معایبی باشد که می‌تواند برای پردازش زبان طبیعی منظور کرد.\n\nموانع اساسی\nنیاز به درک معانی: رایانه برای آن که بتواند برداشت درستی از جمله‌ای داشته باشد و اطلاعات نهفته در آن جمله را درک کند، گاهی لازم است که برداشتی از معنای کلمات موجود در جمله داشته باشد و تنها آشنایی با دستور زبان کافی نباشد؛ مثلاً جمله حسن سیب را نخورد برای این‌که کال بود. و جملهٔ حسن سیب را نخورد برای این‌که سیر بود. ساختار دستوریِ کاملاً یکسانی دارند و تشخیص این‌که کلمات «کال» و «سیر» به «حسن» برمی‌گردند یا به «سیب»، بدون داشتن اطلاعات قبلی دربارهٔ ماهیت «حسن» و «سیب» ممکن نیست.\nدقیق نبودن دستور زبان‌ها: دستورِ هیچ زبانی آن‌قدر دقیق نیست که با استفاده از قواعد دستوری همیشه بتوان به نقش هریک از اجزای جمله‌های آن زبان پی برد.\n\nپردازش زبان‌های طبیعی آمارگرا\nپردازش زبان‌های طبیعی به‌شکل آمارگرا عبارت است از استفاده از روش‌های تصادفی، احتمالاتی و آماری برای حل مسائلی مانند آنچه در بالا ذکر شد. به‌ویژه از این روش‌ها برای حل مسائلی استفاده می‌کنند که ناشی از طولانی بودن جملات و زیاد بودن تعداد حالات ممکن برای نقش کلمات هستند. این روش‌ها معمولاً مبتنی بر نمونه‌های متنی و مدل‌های مارکف هستند.\n\nکارکردهای مهم پردازش زبان‌های طبیعی\nخلاصه‌سازی خودکار\nاستخراج اطلاعات\nبازیابی اطلاعات\nترجمه ماشینی\nتشخیص نوری نویسه‌ها\nتشخیص گفتار\nویرایش\n\nجستارهای وابسته\nهوش مصنوعی\nزبان‌شناسی محاسباتی\nترجمهٔ ماشینی\nمنطق فازی\nمحاسبات نرم\nفراوانی وزنی تی‌اف-آی‌دی‌اف\n\nمنابع\nپیوند به بیرون\nمرجع دادگان زبان فارسی پیکره‌های مورد استفاده در پردازش رایانه‌ای زبان فارسی\nمرکز مطالعات زبان و اطلاعات، استانفورد\nتهیهٔ بانک پرحجم واژگان برای کاربرد در نظام‌های متن‌سازی و سازه‌یابی و بازیابی اطلاعات، ترجمهٔ سید مهدی سمائی، مرکز اطلاعات و مدارک علمی ایران\nکتاب زبان، پیوستگی و صورت"
    },
    {
        "title": "شبکه_عصبی_مصنوعی",
        "text": "شبکه‌های عصبی مصنوعی (Artificial Neural Networks - ANN) یا به زبان ساده‌تر شبکه‌های عصبی سیستم‌ها و روش‌های محاسباتی نوین برای یادگیری ماشینی، نمایش دانش و در انتها اعمال دانش به دست آمده در جهت بیش‌بینی پاسخ‌های خروجی از سامانه‌های پیچیده هستند. ایدهٔ اصلی این گونه شبکه‌ها تا حدودی الهام‌گرفته از شیوهٔ کارکرد سیستم عصبی زیستی برای پردازش داده‌ها و اطلاعات به منظور یادگیری و ایجاد دانش می‌باشد. عنصر کلیدی این ایده، ایجاد ساختارهایی جدید برای سامانهٔ پردازش اطلاعات است. \nاین سیستم از شمار زیادی عناصر پردازشی فوق‌العاده بهم‌پیوسته با نام نورون تشکیل شده که برای حل یک مسئله با هم هماهنگ عمل می‌کنند و توسط سیناپس‌ها (ارتباطات الکترومغناطیسی) اطلاعات را منتقل می‌کنند. در این شبکه‌ها اگر یک سلول آسیب ببیند بقیه سلول‌ها می‌توانند نبود آن را جبران کرده، و نیز در بازسازی آن سهیم باشند. این شبکه‌ها قادر به یادگیری‌اند؛ مثلاً با اعمال سوزش به سلول‌های عصبی لامسه، سلول‌ها یادمی‌گیرند که به طرف جسم داغ نروند و با این الگوریتم سیستم می‌آموزد که خطای خود را اصلاح کند. یادگیری در این سیستم‌ها به صورت تطبیقی صورت می‌گیرد، یعنی با استفاده از مثال‌ها وزن سیناپس‌ها به گونه‌ای تغییر می‌کند که در صورت دادن ورودی‌های جدید، سیستم پاسخ درستی تولید کند.\n\nزمینه\nفلسفهٔ اصلی شبکهٔ عصبی مصنوعی، مدل کردن ویژگی‌های پردازشی مغز انسان برای تقریب زدن روش‌های معمول محاسباتی با روش پردازش زیستی است. به بیان دیگر، شبکهٔ عصبی مصنوعی روشی است که دانش ارتباط بین چند مجموعهٔ داده را از طریق آموزش فراگرفته و برای استفاده در موارد مشابه ذخیره می‌کند. این پردازنده از دو جهت مشابه مغز انسان عمل می‌کند:\n\nیادگیری شبکهٔ عصبی از طریق آموزش صورت می‌گیرد.\nوزن‌دهی مشابه با سیستم ذخیره‌سازی اطلاعات، در شبکهٔ عصبی مغز انسان انجام می‌گیرد.\n\nتعریف\nیک شبکهٔ عصبی مصنوعی، از سه لایهٔ ورودی، خروجی و پردازش تشکیل می‌شود. هر لایه شامل گروهی از سلول‌های عصبی (نورون) است که عموماً با کلیهٔ نورون‌های لایه‌های دیگر در ارتباط هستند، مگر این که کاربر ارتباط بین نورون‌ها را محدود کند؛ ولی نورون‌های هر لایه با سایر نورون‌های همان لایه، ارتباطی ندارند.\nنورون کوچک‌ترین واحد پردازشگر اطلاعات است که اساس عملکرد شبکه‌های عصبی را تشکیل می‌دهد. یک شبکهٔ عصبی مجموعه‌ای از نورون‌هاست که با قرار گرفتن در لایه‌های مختلف، معماری خاصی را بر مبنای ارتباطات بین نورون‌ها در لایه‌های مختلف تشکیل می‌دهند. نورون می‌تواند یک تابع ریاضی غیرخطی باشد، در نتیجه یک شبکهٔ عصبی که از اجتماع این نورون‌ها تشکیل می‌شود، نیز می‌تواند یک سامانهٔ کاملاً پیچیده و غیرخطی باشد. در شبکهٔ عصبی هر نورون به‌طور مستقل عمل می‌کند و رفتار کلی شبکه، برآیند رفتار نورون‌های متعدد است. به عبارت دیگر، نورون‌ها در یک روند همکاری، یکدیگر را تصحیح می‌کنند.\n\nکاربرد\nبا استفاده از دانش برنامه‌نویسی رایانه می‌توان ساختار داده‌ای طراحی کرد که همانند یک نورون عمل نماید. سپس با ایجاد شبکه‌ای از این نورون‌های مصنوعی به هم پیوسته، ایجاد یک الگوریتم آموزشی برای شبکه و اعمال این الگوریتم به شبکه آن را آموزش داد.\nاین شبکه‌ها برای تخمین و تقریب، کارایی بسیار بالایی از خود نشان داده‌اند. گستره کاربرد این مدل‌های ریاضی بر گرفته از عملکرد مغز انسان، بسیار وسیع می‌باشد که به عنوان چند نمونه کوچک می‌توان استفاده از این ابزار ریاضی در پردازش سیگنال‌های بیولوژیکی، مخابراتی و الکترونیکی تا کمک در نجوم و فضانوردی را نام برد.\nاگر یک شبکه را هم‌ارز با یک گراف بدانیم، فرایند آموزش شبکه تعیین نمودن وزن هر یال و base اولیهٔ خواهد بود.\n\nیادگیری\nیادگیری ماشینی با نظارت (supervised learning) به دنبال تابعی از میان یک سری توابع هست که تابع هزینه (loss function) داده‌ها را بهینه سازد. به عنوان مثال در مسئله رگرسیون تابع هزینه می‌تواند اختلاف بین پیش‌بینی و مقدار واقعی خروجی به توان دو باشد، یا در مسئله طبقه‌بندی ضرر منفی لگاریتم احتمال خروجی باشد. مشکلی که در یادگیری شبکه‌های عصبی وجود دارد این است که این مسئله بهینه‌سازی دیگر محدب (convex) نیست. ازین رو با مشکل کمینه‌های محلی روبرو هستیم. یکی از روش‌های متداول حل مسئله بهینه‌سازی در شبکه‌های عصبی بازگشت به عقب یا همان back propagation است. روش بازگشت به عقب گرادیانِ تابع هزینه را برای تمام وزن‌های شبکه عصبی محاسبه می‌کند و بعد از روش‌های گرادیان کاهشی (gradient descent) برای پیدا کردن مجموعه وزن‌های بهینه استفاده می‌کند. روش‌های گرادیان کاهشی سعی می‌کنند به صورت متناوب در خلاف جهت گرادیان حرکت کنند و با این کار تابع هزینه را به حداقل برسانند. پیدا کردن گرادیانِ لایه آخر ساده است و با استفاده از مشتق جزئی به‌دست می‌آید. گرادیانِ لایه‌های میانی اما به صورت مستقیم به‌دست نمی‌آید و باید از روش‌هایی مانند قاعده زنجیری در مشتق‌گیری استفاده کرد. روش بازگشت به عقب از قاعده زنجیری برای محاسبه گرادیان‌ها استفاده می‌کند و همان‌طور که در پایین خواهیم دید، این روش به صورت متناوب گرادیان‌ها را از بالاترین لایه شروع کرده آن‌ها را در لایه‌های پایینتر «پخش» می‌کند.\n\nبازگشت به عقب (Backpropagation)، روشی برا محاسبه گرادیانها\nبرای سلول عصبی \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n ورودیی که از سلول عصبی \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n به این سلول وارد می‌شود را با \n  \n    \n      \n        \n          b\n          \n            p\n            c\n          \n        \n      \n    \n    {\\displaystyle b_{pc}}\n  \n نشان می‌دهیم. وزن این ورودی \n  \n    \n      \n        \n          w\n          \n            p\n            c\n          \n        \n      \n    \n    {\\displaystyle w_{pc}}\n  \n است و مجموع ضرب ورودی‌ها با وزنهایشان را با \n  \n    \n      \n        \n          a\n          \n            c\n          \n        \n      \n    \n    {\\displaystyle a_{c}}\n  \n نمایش می‌دهیم، به این معنی که \n  \n    \n      \n        \n          a\n          \n            c\n          \n        \n        =\n        \n          ∑\n          \n            p\n          \n        \n        \n          w\n          \n            p\n            c\n          \n        \n        ×\n        \n          b\n          \n            p\n            c\n          \n        \n      \n    \n    {\\displaystyle a_{c}=\\sum _{p}w_{pc}\\times b_{pc}}\n  \n. حال باید بر روی \n  \n    \n      \n        \n          a\n          \n            c\n          \n        \n      \n    \n    {\\displaystyle a_{c}}\n  \n تابعی غیر خطی اعمال کنیم این تابع را \n  \n    \n      \n        \n          θ\n          \n            c\n          \n        \n      \n    \n    {\\displaystyle \\theta _{c}}\n  \n می‌نامیم و خروجی آن را با \n  \n    \n      \n        \n          b\n          \n            c\n          \n        \n      \n    \n    {\\displaystyle b_{c}}\n  \n نمایش می‌دهیم یعنی \n  \n    \n      \n        \n          b\n          \n            c\n          \n        \n        =\n        \n          θ\n          \n            c\n          \n        \n        (\n        \n          a\n          \n            c\n          \n        \n        )\n      \n    \n    {\\displaystyle b_{c}=\\theta _{c}(a_{c})}\n  \n. به همین شکل خروجیی که از سلول عصبی \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n خارج شده و به سلول \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n وارد می‌شود را با \n  \n    \n      \n        \n          b\n          \n            c\n            n\n          \n        \n      \n    \n    {\\displaystyle b_{cn}}\n  \n نمایش می‌دهیم و وزن آن را \n  \n    \n      \n        \n          w\n          \n            c\n            n\n          \n        \n      \n    \n    {\\displaystyle w_{cn}}\n  \n می‌نامیم. حال تمام وزن‌های این شبکه عصبی را در مجموعه‌ای به اسم \n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n  \n می‌گنجانیم، هدف یادگیری این وزنهاست. اگر ورودی ما \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n باشد و خروجی \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n و خروجی شبکه عصبی ما \n  \n    \n      \n        \n          h\n          \n            W\n          \n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle h_{W}(x)}\n  \n، هدف پیدا کردن \n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n  \n است به قسمی که برای تمام داده‌ها \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n و \n  \n    \n      \n        \n          h\n          \n            W\n          \n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle h_{W}(x)}\n  \n به هم خیلی نزدیک شوند. به عبارت دیگر هدف کوچک کردن یک تابع هزینه بر روی تمام داده هاست، اگر داده‌ها را با \n  \n    \n      \n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        \n          y\n          \n            1\n          \n        \n        )\n        ,\n        ⋯\n        ,\n        (\n        \n          x\n          \n            n\n          \n        \n        ,\n        \n          y\n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle (x_{1},y_{1}),\\cdots ,(x_{n},y_{n})}\n  \n و تابع هزینه را با \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  \n نشان دهیم هدف کمینه کردن تابع پایین است:\n\nبه عنوان مثال اگر مسئله رگرسیون است برای \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  \n می‌توانیم خطای مربعات را در نظر بگیریم و اگر مسئله دسته‌بندی است برای \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  \n می‌شود منفی لگاریتم درست نمایی را استفاده کرد.\nبرای به‌دست آوردن کمینه \n  \n    \n      \n        Q\n        (\n        W\n        )\n      \n    \n    {\\displaystyle Q(W)}\n  \n باید از روش گرادیان کاهشی استفاده کرد، به این معنی که گرادیان تابع را حساب کرده، کمی در خلاف جهت آن حرکت کرده و این کار را آنقدر ادامه داد تا تابع هزینه خیلی کوچک شود. روش بازگشت به عقب در واقع روشی برای پیدا کردن گرادیان تابع \n  \n    \n      \n        Q\n        (\n        W\n        )\n      \n    \n    {\\displaystyle Q(W)}\n  \n است.\nحال فرض کنیم می‌خواهیم گرادیان تابع \n  \n    \n      \n        Q\n        (\n        W\n        )\n      \n    \n    {\\displaystyle Q(W)}\n  \n را نسبت به وزن \n  \n    \n      \n        \n          w\n          \n            p\n            c\n          \n        \n      \n    \n    {\\displaystyle w_{pc}}\n  \n به‌دست بیاوریم. برای این کار نیاز به قاعده زنجیری در مشتق‌گیری داریم. قاعده زنجیری به این شکل کار می‌کند: اگر تابعی داشته باشیم به اسم \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n که وابسته به سه ورودی \n  \n    \n      \n        u\n      \n    \n    {\\displaystyle u}\n  \n، \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n و \n  \n    \n      \n        w\n      \n    \n    {\\displaystyle w}\n  \n باشد و هرکدام از این سه ورودی به نوبه خود وابسته به \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n باشند، مشتق \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n به \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n به این شکل محاسبه می‌شود:\n\nبا استفاده از این قاعده زنجیری روش بازگشت به عقب را به این شکل دنبال می‌کنیم:\n\nهمان‌طور که در خط پیشین دیدیم برای به‌دست آوردن گرادیان نسبت به \n  \n    \n      \n        \n          w\n          \n            p\n            c\n          \n        \n      \n    \n    {\\displaystyle w_{pc}}\n  \n به دو مقدار نیاز داریم ورودی به سلول عصبی \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n از سلول عصبی \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n که همان \n  \n    \n      \n        \n          b\n          \n            p\n          \n        \n      \n    \n    {\\displaystyle b_{p}}\n  \n است و راحت به‌دست می‌آید و \n  \n    \n      \n        \n          δ\n          \n            c\n          \n        \n      \n    \n    {\\displaystyle \\delta _{c}}\n  \n که از روش بازگشتی به‌دست می‌آید و بستگی به \n  \n    \n      \n        δ\n      \n    \n    {\\displaystyle \\delta }\n  \nهایی لایه بعد دارد که سلول \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \nبه آن‌ها وصل است، به‌طور دقیق‌تر \n  \n    \n      \n        \n          δ\n          \n            c\n          \n        \n        =\n        \n          (\n          \n            \n              ∑\n              \n                n\n              \n            \n            \n              w\n              \n                c\n                n\n              \n            \n            \n              δ\n              \n                n\n              \n            \n          \n          )\n        \n        ×\n        \n          \n            \n              \n                θ\n                ´\n              \n            \n          \n          \n            c\n          \n        \n        (\n        \n          a\n          \n            c\n          \n        \n        )\n      \n    \n    {\\displaystyle \\delta _{c}=\\left(\\sum _{n}w_{cn}\\delta _{n}\\right)\\times {\\acute {\\theta }}_{c}(a_{c})}\n  \n.\nروش بازگشتی برای به‌دست آوردن \n  \n    \n      \n        δ\n      \n    \n    {\\displaystyle \\delta }\n  \nها به این شکل کار می‌کند که ابتدا \n  \n    \n      \n        δ\n      \n    \n    {\\displaystyle \\delta }\n  \n را برای سلول‌های لایه خروجی حساب می‌کنیم، و بعد لایه‌ها را به نوبت پایین می‌آئیم و برای هر سلول \n  \n    \n      \n        δ\n      \n    \n    {\\displaystyle \\delta }\n  \n آن را با ترکیت \n  \n    \n      \n        δ\n      \n    \n    {\\displaystyle \\delta }\n  \nهای لایه‌های بالایی آن طبق فرمول حساب می‌کنیم. محاسبه کردن \n  \n    \n      \n        δ\n      \n    \n    {\\displaystyle \\delta }\n  \n برای لایه خروجی آسان است و مستقیماً با مشتق گرفتن از \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  \n به‌دست می‌آید.\n\nتاریخچه شبکه‌های عصبی مصنوعی\nاز قرن نوزدهم به‌طور همزمان اما جداگانه، از سویی نوروفیزیولوژیست‌ها سعی کردند سیستم یادگیری و تجزیه و تحلیل مغز را کشف کنند، و از سوی دیگر ریاضیدانان تلاش کردند مدل ریاضی ای بسازند که قابلیت فراگیری و تجزیه و تحلیل عمومی مسائل را دارا باشد. اولین کوشش‌ها در شبیه‌سازی با استفاده از یک مدل منطقی در اوایل دههٔ ۱۹۴۰ توسط وارن مک‌کالک و والتر پیتز انجام شد که امروزه بلوک اصلی سازنده اکثر شبکه‌های عصبی مصنوعی است. عملکرد این مدل مبتنی بر جمع ورودی‌ها و ایجاد خروجی با استفاده از شبکه‌ای از نورون‌ها است. اگر حاصل جمع ورودی‌ها از مقدار آستانه بیشتر باشد، اصطلاحاً نورون برانگیخته می‌شود. نتیجه این مدل اجرای ترکیبی از توابع منطقی بود.\nدر سال ۱۹۴۹ دونالد هب قانون یادگیری را برای شبکه‌های عصبی طراحی کرد. در سال ۱۹۵۸ شبکه پرسپترون توسط روزنبلات معرفی گردید. این شبکه نظیر واحدهای مدل شده قبلی بود. پرسپترون دارای سه لایه است که شامل لایهٔ ورودی، لایهٔ خروجی و لایهٔ میانی می‌شود. این سیستم می‌تواند یاد بگیرد که با روشی تکرارشونده وزن‌ها را به گونه‌ای تنظیم کند که شبکه توان بازتولید جفت‌های ورودی و خروجی را داشته‌باشد. روش دیگر، مدل خطی تطبیقی نورون است که در سال ۱۹۶۰ توسط برنارد ویدرو و مارسیان هاف در دانشگاه استنفورد) به وجود آمد که اولین شبکه‌های عصبی به کار گرفته شده در مسائل واقعی بودند. آدالاین یک دستگاه الکترونیکی بود که از اجزای ساده‌ای تشکیل شده بود، روشی که برای آموزش استفاده می‌شد با پرسپترون فرق داشت.\nدر سال ۱۹۶۹ میسکی و پاپرت کتابی نوشتند که محدودیت‌های سیستم‌های تک لایه و چند لایه پرسپترون را تشریح کردند. نتیجه این کتاب پیش داوری و قطع سرمایه‌گذاری برای تحقیقات در زمینه شبیه‌سازی شبکه‌های عصبی بود. آن‌ها با طرح اینکه طرح پرسپترون قادر به حل هیچ مسئله جالبی نمی‌باشد، تحقیقات در این زمینه را برای مدت چندین سال متوقف کردند.\nبا وجود این‌که اشتیاق عمومی و سرمایه‌گذاری‌های موجود به حداقل خود رسیده بود، برخی محققان تحقیقات خود را برای ساخت ماشین‌هایی که توانایی حل مسائلی از قبیل تشخیص الگو را داشته باشند، ادامه دادند. از جمله گراسبگ که شبکه‌ای تحت عنوان Avalanch را برای تشخیص صحبت پیوسته و کنترل دست ربات مطرح کرد. همچنین او با همکاری کارپنتر شبکه‌های نظریه تشدید انطباقی را بنا نهادند که با مدل‌های طبیعی تفاوت داشت. اندرسون و کوهونن نیز از اشخاصی بودند که تکنیک‌هایی برای یادگیری ایجاد کردند. ورباس در سال ۱۹۷۴ شیوه آموزش پس انتشار خطا را ایجاد کرد که یک شبکه پرسپترون چندلایه البته با قوانین نیرومندتر آموزشی بود.\nپیشرفت‌هایی که در سال ۱۹۷۰ تا ۱۹۸۰ به‌دست آمد، برای جلب توجه به شبکه‌های عصبی بسیار مهم بود. برخی فاکتورها نیز در تشدید این مسئله دخالت داشتند، از جمله کتاب‌ها و کنفرانس‌های وسیعی که برای مردم در رشته‌های متنوع ارائه شد. امروز نیز تحولات زیادی در تکنولوژی ANN ایجاد شده‌است.\n\nجستارهای وابسته\nشبکه عصبی پیچشی\nحذف تصادفی\nبازگشت به عقب\nگرادیان کاهشی تصادفی\nقاعده زنجیری\n\nپانویس\nمنابع\nفاست، لوران (۱۳۹۲). مبانی شبکه‌های عصبی. ترجمهٔ هادی ویسی، کبری مفاخری و سعید باقری شورکی. نشر نص. شابک ۹۷۸-۹۶۴-۴۱۰-۲۱۵-۸.\n\n\n== پیوند به بیرون =="
    }
]